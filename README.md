# LLM Content Evaluator - KI-gestÃ¼tzte Inhaltsbewertung

ğŸ¯ **Produktive FastAPI-Anwendung** mit **LLM as Judge** Methodologie zur automatisierten Bewertung von Bildungsinhalten mit KI-gestÃ¼tzter Analyse, deutschen Rechtsstandards und pÃ¤dagogischen QualitÃ¤tskriterien.

## ğŸš€ Features

- âœ… **500+ Bewertungsindikatoren** in 70+ Teilschemas fÃ¼r umfassende Compliance-PrÃ¼fung
- âœ… **4 Master-Gates**: Strafrecht, Jugendschutz, PersÃ¶nlichkeitsrechte, Datenschutz (kombinieren jeweils a/b Kataloge)
- âœ… **4 Schema-Typen**: Ordinal, Checklist, Binary Gates, Derived (mit rekursiver UnterstÃ¼tzung)
- âœ… **LLM as Judge Methodologie** mit OpenAI GPT-4 Integration
- âœ… **Context-Awareness**: Unterscheidung zwischen UGC (content-only) und kommerziellen Plattformen (full compliance)
- âœ… **Parallele Evaluierung**: Mehrere Schemas werden gleichzeitig verarbeitet (max. 20 parallele LLM-Calls, konfigurierbar)
- âœ… **Request-Caching**: Wiederverwendung bereits berechneter Schemas â€“ spart LLM-Kosten und reduziert Latenz
- âœ… **Singleton-Engine**: YAML-Schemas werden einmalig beim API-Start geladen
- âœ… **Deutsche RechtskonformitÃ¤t**: StGB, DSGVO, JuSchG, JMStV, DSA, AVMD-RL, EU-KI-VO
- âœ… **PÃ¤dagogische QualitÃ¤t**: Didaktik, NeutralitÃ¤t, Sachrichtigkeit, AktualitÃ¤t
- âœ… **Modulare QualitÃ¤ts-Gates**: `neutrality_gate`, `factual_accuracy_gate`, `actuality_gate`, `media_appropriate_gate`, `linguistic_appropriateness_gate`, `didactics_gate`
- âœ… **Jugendschutz**: 278 Indikatoren fÃ¼r Altersfreigaben (FSK 0/6/12/16/18 + AVS)
- âœ… **RESTful API** mit vollstÃ¤ndiger OpenAPI/Swagger Dokumentation
- âœ… **Produktionsbereit** mit Error Handling und Validation
- âœ… **Flexible Ausgabe**: Detaillierte BegrÃ¼ndungen und Kriterien-Breakdown

## ğŸ“‹ Ãœbersicht aller Schemas

### QualitÃ¤tsbewertung (13 Schemas)

| Schema ID | Typ | Beschreibung | Skala | Kriterien |
|-----------|-----|--------------|-------|-----------|
| `sachrichtigkeit_new` | Checklist | Detaillierte Sachrichtigkeit | 10 Kriterien | Faktentreue, Quellenangaben, Wissenschaftlichkeit |
| `neutralitaet_new` | Checklist | Detaillierte NeutralitÃ¤t | 10 Kriterien | Ausgewogenheit, ObjektivitÃ¤t, Meinungsvielfalt |
| `aktualitaet_new` | Checklist | Detaillierte AktualitÃ¤t | 10 Kriterien | ZeitgemÃ¤ÃŸheit, Relevanz, Updates |
| `didaktik_methodik_new` | Checklist | Detaillierte Didaktik | 10 Kriterien | Lernziele, Methoden, VerstÃ¤ndlichkeit |
| `sprachliche_angemessenheit_new` | Checklist | Detaillierte Sprache | 10 Kriterien | VerstÃ¤ndlichkeit, Stil, Zielgruppe, Grammatik |
| `medial_passend_new` | Checklist | Detaillierte Mediale Passung | 10 Kriterien | Technische QualitÃ¤t, InteraktivitÃ¤t, ZugÃ¤nglichkeit |
| `sachrichtigkeit_old` | Ordinal | Sachrichtigkeit (0-5) | 6 Stufen | Kompakte Bewertung der Faktentreue |
| `neutralitaet_old` | Ordinal | NeutralitÃ¤t (0-5) | 6 Stufen | Kompakte Bewertung der Ausgewogenheit |
| `aktualitaet_old` | Ordinal | AktualitÃ¤t (0-5) | 6 Stufen | Kompakte Bewertung der ZeitgemÃ¤ÃŸheit |
| `sprachliche_angemessenheit_old` | Ordinal | Sprache (0-5) | 6 Stufen | VerstÃ¤ndlichkeit, Stil, Zielgruppe |
| `didaktik_methodik_old` | Ordinal | Didaktik (0-5) | 6 Stufen | Kompakte pÃ¤dagogische Bewertung |
| `medial_passend_old` | Ordinal | Mediale Passung (0-5) | 6 Stufen | Medieneignung, Darstellung |
| `overall_quality` | Derived | GesamtqualitÃ¤t | 0.0-5.0 | Gewichtete Kombination aller Dimensionen |

### Compliance & Rechtssicherheit - Master-Gates

Die API bietet **4 Master-Gates**, die jeweils die a/b Kataloge der Hauptrechtsbereiche kombinieren:

| Schema ID | Typ | Kombiniert | Output | Indikatoren | Beschreibung |
|-----------|-----|------------|--------|-------------|--------------|  
| `criminal_law_gate` | Master | 1A + 1B | 0-2 | 92 | **Strafrecht**: ILLEGAL (0) / KONTEXTABHÃ„NGIG (1) / LEGAL (2) |
| `protection_of_minors_gate` | Master | 2A + 2B | 0-18, 100 | 278 | **Jugendschutz**: FSK-Freigaben (0,6,12,16,18) + AVS (100) |
| `personal_law_gate` | Master | 3A + 3B | 0-3 | 88 | **PersÃ¶nlichkeitsrechte**: KRITISCH (0) / STRUKTURELL (1) / CONTENT (2) / COMPLIANT (3) |
| `data_privacy_gate` | Master | 4A + 4B | 0-3 | 87 | **Datenschutz**: KRITISCH (0) / TRANSPARENZ (1) / DSGVO (2) / COMPLIANT (3) |

**Sub-Gates** (fÃ¼r granulare PrÃ¼fungen):

| Schema ID | Typ | Beschreibung | Rechtsbasis | Indikatoren |
|-----------|-----|--------------|-------------|-------------|
| `criminal_law_1a_gate` | Binary | **Strafrecht 1A**: Per se illegal (Hard Illegal / AUA) | StGB, JMStV Â§4 | 49 |
| `criminal_law_1b_gate` | Binary | **Strafrecht 1B**: KontextabhÃ¤ngig strafbar | StGB, UrhG, BDSG | 43 |
| `protection_of_minors_2a_gate` | Binary | **Jugendschutz 2A**: JugendgefÃ¤hrdend (AVS-Pflicht) | JMStV Â§4 Abs.2 | 37 |
| `protection_of_minors_2b_gate` | Derived | **Jugendschutz 2B**: EntwicklungsbeeintrÃ¤chtigend (FSK) | JMStV Â§5, JuSchG Â§14 | 241 |
| `personal_law_3a_gate` | Binary | **PersÃ¶nlichkeitsrechte 3A**: Individuelle Verletzungen | GG, BGB, KUG, StGB | 44 |
| `personal_law_3b_gate` | Binary | **PersÃ¶nlichkeitsrechte 3B**: Strukturelle Vorsorge | JuSchG Â§24a, DSA | 44 |
| `data_privacy_4a_gate` | Binary | **Datenschutz 4A**: Profiling & Einwilligung | DSGVO, TDDDG | 50 |
| `data_privacy_4b_gate` | Binary | **Datenschutz 4B**: Transparenz & KI-Kennzeichnung | MStV, DSA, EU-KI-VO | 37 |

**Hinweis**: Teilschemas (z.B. `*_part1`, `*_part2`) sind interne Bausteine und werden in der API-Ãœbersicht standardmÃ¤ÃŸig ausgeblendet (mit `?include_parts=true` sichtbar).

## ğŸ› ï¸ Installation & Setup

### Voraussetzungen
- Python 3.8+
- OpenAI API Key (fÃ¼r KI-basierte Bewertung)
- FastAPI, Uvicorn, Pydantic (automatisch installiert)

### Schnellstart

```bash
# Repository klonen
git clone <repository-url>
cd api-scoring-quality/api-eval-25

# Umgebung einrichten
cp .env.example .env
# .env mit OpenAI API Key bearbeiten:
# OPENAI_API_KEY=your_api_key_here

# Dependencies installieren
pip install fastapi uvicorn openai pydantic loguru pyyaml

# Server starten
python main.py
```

ğŸŒ **Server lÃ¤uft auf: http://localhost:8001**  
ğŸ“š **API Dokumentation: http://localhost:8001/docs**  
ğŸ” **Alternative Docs: http://localhost:8001/redoc**

### ğŸ”„ Startup Lifecycle

FastAPI initialisiert im `main.py` eine Singleton-Instanz der `EvaluationEngine` wÃ¤hrend des Lifespan-Events:

```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    initialize_engine("schemes")  # lÃ¤dt alle YAMLs einmalig
    yield
    shutdown_engine()
```

So werden die ~59 YAML-Dateien nur einmal beim Start geladen â€“ alle Endpoints greifen auf dieselbe Instanz zu.

### ğŸ“‰ Logging & Monitoring

`loguru` unterscheidet nun zwischen:
- `INFO`: High-Level Ereignisse (Startup, Gesamtsumme Schemas)
- `DEBUG`: Detail-Informationen (Cache_hits, Rule-Auswertung, Dependency-Resultate)
- `ERROR`: Fehlgeschlagene Bewertungen

Setze `LOG_LEVEL=DEBUG` in der `.env`, um detaillierte Cache-Hits und RegelprÃ¼fungen mitzuschreiben.

### âš™ï¸ Umgebungsvariablen

Erstelle eine `.env` Datei im Projektverzeichnis:

```bash
# LLM Settings
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# Concurrency Control
MAX_CONCURRENT_LLM_CALLS=20

# APP Settings
LOG_LEVEL=INFO
SCHEMES_DIR=schemes

# API Configuration
API_HOST=0.0.0.0
API_PORT=8001
API_DEBUG=true

# Request Timeouts
HTTP_TIMEOUT_SECONDS=30
OPENAI_TIMEOUT_SECONDS=60
```

**Wichtige Variablen:**
- `MAX_CONCURRENT_LLM_CALLS`: Begrenzt parallele LLM-Aufrufe (Standard: 20)
  - Verhindert Rate Limits bei groÃŸen Schemas (z.B. Gate 2B mit 50+ Teilschemas)
  - HÃ¶here Werte = schneller, aber mehr API-Last
  - Niedrigere Werte = langsamer, aber stabiler

## ğŸ”— API Endpoints

### ğŸ¥ Health Check
```http
GET /health
```
**Status:** âœ… FunktionsfÃ¤hig  
**Zweck:** API-Status und geladene Schemas prÃ¼fen

### ğŸ“‹ Schema-Ãœbersicht  
```http
GET /schemes?include_parts=false
```
**Status:** âœ… FunktionsfÃ¤hig  
**Zweck:** Alle verfÃ¼gbaren Bewertungsschemas auflisten (standardmÃ¤ÃŸig nur Master/Gate-Schemas)

**Query-Parameter:**
- `include_parts` (default: `false`): 
  - `false`: Nur Master-Gates und Sub-Gates (empfohlen fÃ¼r Endnutzer)
  - `true`: Alle Schemas inkl. interner Teilschemas (*_part1, *_part2, etc.)
- `context_type` (optional): Filtert serverseitig nach Scope ("content", "platform", "both") und spiegelt damit die Evaluationslogik.

### ğŸ¯ Text-Bewertung
```http
POST /evaluate
```
**Status:** âœ… FunktionsfÃ¤hig  
**Zweck:** KI-gestÃ¼tzte Bewertung von Bildungsinhalten

**Beispiel-Request:**
```json
{
    "text": "Die deutsche Wiedervereinigung war ein komplexer politischer Prozess...",
    "schemes": ["neutralitaet_new", "sachrichtigkeit_old", "rechtliche_compliance"],
    "include_reasoning": true
}
```

**Beispiel-Response:**
```json
{
    "results": [
        {
            "scheme_id": "neutralitaet_new",
            "value": 4.2,
            "label": "Weitgehend neutral",
            "confidence": 0.88,
            "reasoning": "Der Text stellt verschiedene Perspektiven ausgewogen dar...",
            "criteria": {
                "ausgewogenheit": {"value": 4, "reasoning": "Mehrere Standpunkte berÃ¼cksichtigt"},
                "objektivitaet": {"value": 4, "reasoning": "Sachliche Darstellung ohne Wertungen"}
            }
        },
        {
            "scheme_id": "sachrichtigkeit_old",
            "value": 3,
            "label": "Inhaltlich Ã¼berwiegend korrekt"
        }
    ],
    "gates_passed": true,
    "overall_score": 3.6,
    "overall_label": "Gut",
    "metadata": {
        "processing_time_ms": 1250,
        "model_used": "gpt-4"
    }
}
```

## ğŸ¯ Context-Awareness (Content vs. Platform vs. Both)

Die API unterscheidet zwischen **reiner Inhaltsbewertung** (fÃ¼r UGC, Blogs) und **voller Platform-Compliance** (fÃ¼r kommerzielle Anbieter).

### Context-Typen

| Context | Scope-Filter | Beschreibung | Anwendungsfall |
|---------|--------------|--------------|----------------|
| `content` (Default) | Nur `content` + `both` | Bewertet nur den **Inhalt** selbst | UGC, Social Media, Blogs, News, YouTube-Videos |
| `platform` | Nur `platform` + `both` | Bewertet **Metadaten & technische MaÃŸnahmen** | Streaming-Plattformen, App Stores, VOD-Dienste |
| `both` | Alle Scopes | **Volle Compliance-PrÃ¼fung** (Inhalt + Plattform) | Audits, Rechtsberatung, kommerzielle Content-PrÃ¼fung |

### Scope-Feld in YAML-Schemas

Jedes Gate-Rule hat ein `scope`-Feld, das die Anwendbarkeit definiert:

```yaml
gate_rules:
  - id: 2B-16-40
    description: "Realistische Gewalt mit Leidfolgen ohne Kontextualisierung"
    scope: content    # Wird bei context_type="content" geprÃ¼ft
    
  - id: 2B-16-08
    description: "Fehlende Alterskennzeichnung nach JuSchG"
    scope: platform   # Wird nur bei context_type="platform" geprÃ¼ft
    
  - id: 2B-16-39
    description: "Belastende Nachrichten ohne Einordnung"
    scope: both       # Wird immer geprÃ¼ft (content + platform)
```

**Scope-Werte:**
- `content`: Inhaltliche Eigenschaften (Gewalt, SexualitÃ¤t, Sprache, Themen)
- `platform`: Technische/organisatorische MaÃŸnahmen (FSK-Label, Jugendschutzprogramme, Zeitsteuerung)
- `both`: Kombination (z.B. "Belastende Inhalte ohne Einordnung" = Inhalt + fehlender Warnhinweis)

### Beispiel: UGC-Bewertung (User-Generated Content)

```json
{
    "text": "brutale Kampfszene in einem Online Video",
    "schemes": ["protection_of_minors_gate"],
    "context_type": "content",
    "include_reasoning": true
}
```

**GeprÃ¼ft werden:**
- âœ… Gewaltdarstellungen (`scope: content`)
- âœ… Sexuelle Inhalte (`scope: content`)
- âœ… Belastende Inhalte ohne Einordnung (`scope: both`)

**Ignoriert werden:**
- âŒ FSK-Kennzeichnung fehlt (`scope: platform`)
- âŒ Jugendschutzprogramm-Signalisierung (`scope: platform`)
- âŒ Zeitsteuerung 20:00-06:00 (`scope: platform`)

**Vorteil:** UGC-Inhalte werden nicht wegen fehlender technischer MaÃŸnahmen abgelehnt!

### Beispiel: Kommerzielle Plattform (Netflix, Amazon Prime)

```json
{
    "text": "Film mit FSK 16 Label, aber keine Zeitsteuerung implementiert",
    "schemes": ["protection_of_minors_gate"],
    "context_type": "platform",
    "include_reasoning": true
}
```

**GeprÃ¼ft werden:**
- âœ… FSK-Kennzeichnung vorhanden? (`scope: platform`)
- âœ… Jugendschutzprogramm-Signalisierung? (`scope: platform`)
- âœ… Zeitsteuerung 22:00-06:00 fÃ¼r FSK 16? (`scope: platform`)
- âœ… Belastende Inhalte ohne Einordnung (`scope: both`)

**Ignoriert werden:**
- âŒ Inhaltliche Gewaltbewertung (`scope: content`) - wird als durch FSK-Label abgedeckt betrachtet

### Beispiel: VollstÃ¤ndiger Audit (Beides)

```json
{
    "text": "...",
    "schemes": ["criminal_law_gate", "protection_of_minors_gate", "data_privacy_gate"],
    "context_type": "both",
    "include_reasoning": true
}
```

**GeprÃ¼ft werden:** Alle Rules unabhÃ¤ngig vom Scope

### Automatische Keyword-Erkennung

Das System klassifiziert Rules automatisch anhand von Keywords in der Beschreibung:

**Content-Rules** (Inhaltliche Eigenschaften):
- Gewalt, Darstellung, Thematisierung, Bedrohung, SexualitÃ¤t
- Brutal, explizit, zeigt, enthÃ¤lt, verherrlicht
- Diskriminierung, Hassrede, Beleidigung

**Platform-Rules** (Technische MaÃŸnahmen):
- Fehlende Kennzeichnung, Keine Altersfreigabe, Unzureichende MaÃŸnahmen
- Zeitsteuerung, Jugendschutzprogramm, FSK-Label, PIN-Schutz
- Meldesystem, Elternkontrollen, Voreinstellungen

**Both-Rules** (Kombination):
- "ohne Einordnung", "ohne Warnhinweis", "ohne Kontextualisierung"
- Inhaltsproblem + fehlende Plattform-MaÃŸnahme

### Best Practice: Context-Typ WÃ¤hlen

| Anwendungsfall | Empfohlener Context | BegrÃ¼ndung |
|----------------|---------------------|------------|
| **Social Media Post** | `content` | Nur Inhalt relevant, keine Plattform-Verantwortung des Posters |
| **YouTube Video (Creator)** | `content` | Creator verantwortlich fÃ¼r Inhalt, nicht fÃ¼r Plattform-Features |
| **Streaming-Dienst (Betreiber)** | `platform` | PrÃ¼fung der technischen JugendschutzmaÃŸnahmen |
| **App Store (Review)** | `platform` | PrÃ¼fung der Metadaten und Kennzeichnungen |
| **Rechtsberatung/Audit** | `both` | VollstÃ¤ndige Compliance-PrÃ¼fung |
| **Content-Moderation** | `content` | Schnelle InhaltsprÃ¼fung ohne Plattform-Overhead |

## ğŸ“– YAML Schema-Parameter - Detaillierte Anleitung

### Grundstruktur aller Schemas

Jedes YAML-Schema folgt einer einheitlichen Grundstruktur:

```yaml
# Eindeutige Identifikation
id: schema_identifier
name: "Benutzerfreundlicher Anzeigename"
description: "Detaillierte Beschreibung des Bewertungszwecks"
dimension: dimension_name  # Technischer Dimensionsname
type: ordinal|checklist|binary_gate|derived
version: "1.0"

# Ausgabeformat definieren
output_range:
  min: 0      # Minimaler Wert
  max: 5      # Maximaler Wert  
  type: int   # int, float oder boolean
  values: [0, 1, 2, 3, 4, 5]  # Optional: Erlaubte Werte
```

**Pflichtfelder:**
- `id`: Eindeutige Schema-ID (keine Leerzeichen, Kleinbuchstaben)
- `name`: Anzeigename fÃ¼r BenutzeroberflÃ¤che
- `type`: Schema-Typ bestimmt Bewertungslogik
- `output_range`: Definiert mÃ¶gliche Ausgabewerte

### Schema-Typen im Detail

#### 1. Ordinal Schema - Anker-basierte Bewertung (0-5 Skala)

Ordinal-Schemas verwenden vordefinierte Anker fÃ¼r konsistente Bewertungen:

```yaml
id: neutralitaet_old
name: "NeutralitÃ¤t (Ordinal)"
description: "Bewertung der politischen und weltanschaulichen NeutralitÃ¤t"
dimension: neutrality
type: ordinal
version: "1.0"

output_range:
  min: 0
  max: 5
  type: int

# Bewertungsstrategie
strategy: first_match  # oder best_fit

# Anker in absteigender Reihenfolge (5 â†’ 0)
anchors:
  - value: 5
    label: "VollstÃ¤ndig neutral"
    criteria: |
      - Alle Standpunkte werden fair dargestellt
      - Keine erkennbare politische Tendenz
      - Ausgewogene Quellenauswahl
      - Objektive Sprache durchgehend
      
  - value: 4
    label: "Weitgehend neutral"
    criteria: |
      - Ãœberwiegend ausgewogene Darstellung
      - Minimale Tendenz erkennbar
      - Verschiedene Perspektiven berÃ¼cksichtigt
      
  - value: 3
    label: "Teilweise neutral"
    criteria: |
      - GrundsÃ¤tzlich um NeutralitÃ¤t bemÃ¼ht
      - Deutliche Tendenz in eine Richtung
      - Nicht alle Standpunkte gleichwertig dargestellt
      
  - value: 2
    label: "Wenig neutral"
    criteria: |
      - Starke Tendenz erkennbar
      - Einseitige Quellenauswahl
      - Gegenpositionen nur oberflÃ¤chlich behandelt
      
  - value: 1
    label: "Einseitig"
    criteria: |
      - Deutlich parteiische Darstellung
      - Wichtige Gegenpositionen fehlen
      - Wertende Sprache dominiert
      
  - value: 0
    label: "Stark einseitig"
    criteria: |
      - Propagandistische Darstellung
      - Keine BerÃ¼cksichtigung anderer Standpunkte
      - Manipulative oder hetzerische Sprache

# Fallback bei unklaren FÃ¤llen
default:
  value: 0
  label: "Unbewertet"
  reasoning: "Keine ausreichenden Informationen fÃ¼r Bewertung"
  confidence: 0.0

# ZusÃ¤tzliche Metadaten
labels:
  "5": "Exzellent neutral"
  "4": "Gut neutral"
  "3": "Akzeptabel"
  "2": "VerbesserungsbedÃ¼rftig"
  "1": "Problematisch"
  "0": "Inakzeptabel"
```

**Strategien:**
- `first_match`: Erste passende Bewertung wird verwendet
- `best_fit`: Beste Ãœbereinstimmung wird gesucht

**VollstÃ¤ndiges Beispiel:** `neutralitaet_old.yaml`

#### 2. Checklist Schema - Kriterien-basierte Bewertung

Checklist-Schemas bewerten anhand gewichteter Einzelkriterien mit **kompakter Strukturbeschreibung**:

```yaml
id: sachrichtigkeit_new
name: "Sachrichtigkeit (Detailliert)"
description: "Umfassende Bewertung der faktischen Korrektheit"
dimension: factuality
type: checklist_additive
version: "1.0"

output_range:
  min: 0.0
  max: 5.0
  type: float

# Einzelkriterien mit strukturierten Werten (NEUE KOMPAKTE STRUKTUR)
items:
  - id: faktentreue
    prompt: "Sind alle Fakten und Aussagen korrekt und verifizierbar?"
    weight: 2.5
    values:
      1: {score: 0.25, description: "Viele falsche oder ungeprÃ¼fte Aussagen"}
      2: {score: 0.5, description: "Einige faktische Fehler oder Ungenauigkeiten"}
      3: {score: 0.75, description: "Ãœberwiegend korrekte Fakten, wenige Fehler"}
      4: {score: 1.0, description: "Alle Fakten korrekt und gut verifizierbar"}
      na: null
      
  - id: quellenangaben
    prompt: "Sind alle Behauptungen mit seriÃ¶sen Quellen belegt?"
    weight: 2.0
    values:
      1: {score: 0.25, description: "Keine oder unzuverlÃ¤ssige Quellenangaben"}
      2: {score: 0.5, description: "Wenige oder teilweise fragwÃ¼rdige Quellen"}
      3: {score: 0.75, description: "Gute Quellenangaben, meist seriÃ¶s"}
      4: {score: 1.0, description: "VollstÃ¤ndige, seriÃ¶se und aktuelle Quellenangaben"}
      na: null

# Aggregation mit gewichtetem Mittelwert
aggregator:
  strategy: weighted_mean
  params:
    missing: ignore
    scale_factor: 5.0  # Skaliert von 0-1 auf 0-5

# Labels fÃ¼r Ausgabe
labels:
  "0.0": "Unzureichend"
  "1.0": "Mangelhaft"
  "2.0": "Ausreichend"
  "3.0": "Befriedigend"
  "4.0": "Gut"
  "5.0": "Sehr gut"
```

**Neue Kompakte Struktur:**
- **Strukturierte Werte:** `{score: 0.25, description: "..."}` statt einfacher Kommentare
- **Bessere LLM-Prompts:** Beschreibungen werden direkt in Bewertungsprompts eingebunden
- **Einheitliche Skalierung:** Alle Kriterien verwenden 1-4 Level mit 0.25-1.0 Scores

**VollstÃ¤ndiges Beispiel:** `sachrichtigkeit_new.yaml`, `neutralitaet_new.yaml`, `sprachliche_angemessenheit_new.yaml`, `medial_passend_new.yaml`

#### 3. Binary Gate - Pass/Fail Bewertung

Binary Gates sind K.O.-Kriterien fÃ¼r Compliance-PrÃ¼fungen:

```yaml
id: strafrecht_gate
name: "Strafrechtliche Unbedenklichkeit"
description: "PrÃ¼fung auf VerstÃ¶ÃŸe gegen deutsches Strafrecht"
dimension: legal_compliance
type: binary_gate
version: "1.0"

output_range:
  values: [true, false]
  type: boolean

# PrÃ¼fkriterien (wird in criteria-Feld dokumentiert)
criteria: |
  Automatische PrÃ¼fung auf strafrechtlich relevante Inhalte:
  - Volksverhetzung (Â§ 130 StGB)
  - Gewaltverherrlichung (Â§ 131 StGB)
  - Beleidigung und Verleumdung (Â§ 185-187 StGB)
  - Bedrohung (Â§ 241 StGB)
  - Verfassungswidrige Symbole (Â§ 86a StGB)

# Gate-Regeln (Reihenfolge wichtig!)
gate_rules:
  - condition: "volksverhetzung"
    action: reject
    reason: "Inhalt enthÃ¤lt volksverhetzende Ã„uÃŸerungen (Â§ 130 StGB)"
    severity: critical
    legal_reference: "Â§ 130 StGB"
    confidence: 0.9
    
  - condition: "gewaltverherrlichung"
    action: reject
    reason: "Inhalt verherrlicht Gewalt (Â§ 131 StGB)"
    severity: critical
    legal_reference: "Â§ 131 StGB"
    confidence: 0.85
    
  - condition: "beleidigung"
    action: reject
    reason: "Inhalt enthÃ¤lt Beleidigungen (Â§ 185-187 StGB)"
    severity: medium
    legal_reference: "Â§ 185-187 StGB"
    confidence: 0.7
    
  - condition: "bedrohung"
    action: reject
    reason: "Inhalt enthÃ¤lt Bedrohungen (Â§ 241 StGB)"
    severity: high
    legal_reference: "Â§ 241 StGB"
    confidence: 0.8

# Standard-Aktion wenn keine Regel greift
default_action: pass

# Automatische Keyword-Erkennung
detection_patterns:
  volksverhetzung:
    - "holocaustleugnung"
    - "rassenhass"
    - "judenhass"
    - "auslÃ¤nder raus"
    - "vernichtung"
    
  gewaltverherrlichung:
    - "folter verherrlichen"
    - "gewalt glorifizieren"
    - "hinrichtung feiern"
    - "sadismus"
    
  beleidigung:
    - "idiot"
    - "schwachkopf"
    - "versager"
    # (Kontext-abhÃ¤ngig)
    
  bedrohung:
    - "ich bringe dich um"
    - "du bist tot"
    - "warte nur ab"

# Severity-Level Definitionen
severity_levels:
  critical: "Schwere Straftaten mit GefÃ¤ngnisstrafe"
  high: "Straftaten mit erheblicher gesellschaftlicher Relevanz"
  medium: "RechtsverstÃ¶ÃŸe mit zivilrechtlichen Konsequenzen"
  low: "GeringfÃ¼gige RechtsverstÃ¶ÃŸe"

# Compliance-Referenzen
compliance_references:
  - "Strafgesetzbuch (StGB)"
  - "Netzwerkdurchsetzungsgesetz (NetzDG)"
  - "Digital Services Act (DSA)"
```

**Gate-Logik:**
1. Regeln werden in Reihenfolge geprÃ¼ft
2. Erste zutreffende Regel bestimmt Ergebnis
3. Bei keiner Regel: `default_action`

**Severity-Levels:**
- `critical`: Sofortige Sperrung erforderlich
- `high`: Manuelle PrÃ¼fung erforderlich
- `medium`: Warnung an Nutzer
- `low`: Hinweis ausreichend

**VollstÃ¤ndiges Beispiel:** `strafrecht_gate.yaml`

#### 4. Derived Schema - Kombination anderer Schemas

Derived Schemas kombinieren Ergebnisse anderer Schemas:

```yaml
id: overall_quality
name: "GesamtqualitÃ¤t"
description: "Gewichtete Kombination aller QualitÃ¤tsdimensionen"
dimension: overall_quality
type: derived
version: "2.0"

output_range:
  min: 0.0
  max: 5.0
  type: float

# AbhÃ¤ngigkeiten (mÃ¼ssen vorher ausgewertet werden)
dependencies:
  - neutralitaet_old
  - aktualitaet_old
  - sachrichtigkeit_old
  - sprachliche_angemessenheit_old
  - didaktik_methodik_old
  - medial_passend_old

# Kombinationsregeln
rules:
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 0
      - dimension: factuality
        operator: ">="
        value: 0
    value: "weighted_average"
    label: "Gewichtete Gesamtbewertung"
    reasoning: "Berechnung basierend auf gewichteten Einzeldimensionen"
    confidence: 0.9
    
    # Gewichtung der Dimensionen
    weights:
      neutrality: 2.0              # NeutralitÃ¤t (wichtig)
      timeliness: 1.5              # AktualitÃ¤t
      factuality: 2.5              # Sachrichtigkeit (sehr wichtig)
      language_appropriateness: 1.5 # Sprachliche Angemessenheit
      pedagogy: 2.0                # Didaktik/Methodik (wichtig)
      media_appropriateness: 1.0    # Mediale Passung
      
  # Spezialregel fÃ¼r niedrige Sachrichtigkeit
  - conditions:
      - dimension: factuality
        operator: "<"
        value: 2.0
    value: 1.0
    label: "Unzureichende Sachrichtigkeit"
    reasoning: "Niedrige Sachrichtigkeit fÃ¼hrt zu schlechter Gesamtbewertung"
    confidence: 0.95

# Fallback
default:
  value: 0.0
  label: "Unbewertet"
  reasoning: "Keine ausreichenden Daten fÃ¼r Gesamtbewertung"
  confidence: 0.0

# Ausgabe-Labels
labels:
  "4.5-5.0": "Exzellente QualitÃ¤t"
  "3.5-4.4": "Gute QualitÃ¤t"
  "2.5-3.4": "Akzeptable QualitÃ¤t"
  "1.5-2.4": "VerbesserungsbedÃ¼rftig"
  "0.0-1.4": "Unzureichende QualitÃ¤t"

# Mathematische Operationen
calculation_method: weighted_average
normalization: true
```

**Kombinationslogik:**
- `weighted_average`: Gewichteter Durchschnitt (fÃ¼r GesamtqualitÃ¤t)
- `sum`: Einfache Summe aller Werte (fÃ¼r Split-Schemas)
- `min`: Minimum aller Werte
- `max`: Maximum aller Werte
- `and_gate`: Alle mÃ¼ssen TRUE sein
- `or_gate`: Mindestens einer TRUE

**Operatoren fÃ¼r Bedingungen:**
- `==`: Gleich
- `!=`: Ungleich
- `>`: GrÃ¶ÃŸer
- `>=`: GrÃ¶ÃŸer oder gleich
- `<`: Kleiner
- `<=`: Kleiner oder gleich
- `in`: Wert in Liste
- `not_in`: Wert nicht in Liste

**Performance-Optimierung:**
- Dependencies werden **parallel ausgefÃ¼hrt** (asyncio.gather) fÃ¼r maximale Geschwindigkeit
- Mehrere Schemas im selben Request werden ebenfalls parallel evaluiert
- Binary Gates: **LLM-Aufrufe laufen parallel**, aber logische Auswertung ist sequenziell (Early Exit bei Fehlschlag im Top-Level)

**Ausgabestruktur fÃ¼r Derived Schemas:**

Derived Schemas geben sowohl die Einzelergebnisse der Dependencies als auch das kombinierte Gesamtergebnis zurÃ¼ck:

```json
{
  "scheme_id": "overall_quality",
  "dimension": "overall_quality",
  "value": 3.85,
  "label": "Gute QualitÃ¤t",
  "reasoning": "Gewichteter Durchschnitt: 3.85/5.0\n\nEinzelbewertungen:\n- neutrality: 4.0 Ã— 2.0\n- factuality: 4.5 Ã— 2.5\n...",
  "confidence": 0.9,
  "scale_info": {
    "type": "derived",
    "method": "weighted_average",
    "dependencies": 6,
    "weights": {"neutrality": 2.0, "factuality": 2.5}
  },
  "criteria": {
    "neutralitaet_old": {
      "dimension": "neutrality",
      "value": 4.0,
      "label": "Weitgehend neutral",
      "weight": 2.0,
      "confidence": 0.88,
      "reasoning": "Der Text stellt verschiedene Perspektiven ausgewogen dar...",
      "scale_info": {
        "type": "ordinal_rubric",
        "range": {"min": 0, "max": 5},
        "anchors": 6
      },
      "criteria": null
    },
    "sachrichtigkeit_new": {
      "dimension": "factuality", 
      "value": 4.5,
      "label": "Hohe Sachrichtigkeit",
      "weight": 2.5,
      "confidence": 0.8,
      "reasoning": "Fakten sind korrekt und gut belegt...",
      "scale_info": {
        "type": "checklist_additive",
        "raw_range": "0.0-1.0",
        "normalized_range": "0.0-5.0"
      },
      "criteria": {
        "fakten_belegt": {
          "name": "Faktische Belege",
          "response": "4",
          "normalized_score": 4.0,
          "weight": 1.0,
          "reasoning": "Alle wichtigen Aussagen sind belegt"
        },
        "quellenangaben": {
          "name": "Quellenangaben",
          "response": "4",
          "normalized_score": 4.0,
          "weight": 1.0,
          "reasoning": "Quellen sind korrekt angegeben"
        }
      }
    }
  }
}
```

**VollstÃ¤ndige Transparenz:** Jedes Dependency-Schema enthÃ¤lt:
- `value`, `label`: Bewertungsergebnis
- `confidence`: Konfidenzwert der Bewertung
- `reasoning`: VollstÃ¤ndige BegrÃ¼ndung (nicht verkÃ¼rzt)
- `scale_info`: Metadaten zum verwendeten Schema-Typ
- `criteria`: Verschachtelte Sub-Kriterien (bei Checklists)

**VollstÃ¤ndiges Beispiel:** `overall_quality.yaml`, `rechtliche_compliance.yaml`

### Erweiterte YAML-Features

#### Conditional Logic (Bedingte Logik)

```yaml
rules:
  # Mehrere Bedingungen (UND-verknÃ¼pft)
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 3
      - dimension: factuality
        operator: ">="
        value: 4
    value: 4.5
    label: "Hohe QualitÃ¤t"
    
  # ODER-VerknÃ¼pfung mit condition_logic
  - condition_logic: "OR"
    conditions:
      - dimension: neutrality
        operator: "=="
        value: 5
      - dimension: factuality
        operator: "=="
        value: 5
    value: 4.0
    label: "Exzellenz in einer Dimension"
```

#### Gate Logic fÃ¼r Binary Schemas

```yaml
# UND-VerknÃ¼pfung (alle Gates mÃ¼ssen TRUE sein)
gate_logic: "AND"

# ODER-VerknÃ¼pfung (mindestens ein Gate TRUE)
gate_logic: "OR"

# Beispiel: Rechtliche Unbedenklichkeit
dependencies:
  - content_gate
  - jugendschutz_gate
  - strafrecht_gate
  - persoenlichkeitsrechte_gate

rules:
  - conditions:
      - dimension: content_safety
        operator: "=="
        value: true
      - dimension: youth_protection
        operator: "=="
        value: true
      - dimension: legal_compliance
        operator: "=="
        value: true
      - dimension: personality_rights
        operator: "=="
        value: true
    value: true
    label: "Rechtlich unbedenklich"
```

#### Regeln fÃ¼r Derived Schema-VerknÃ¼pfungen

**Grundprinzipien:**

1. **Dependencies mÃ¼ssen existieren**: Alle Schemas in `dependencies` mÃ¼ssen als YAML-Dateien vorhanden sein
2. **Keine ZirkelbezÃ¼ge**: Schema A darf nicht direkt oder indirekt auf sich selbst verweisen
3. **Dimension-Matching**: Die `dimension` in Bedingungen muss mit der `dimension` der Dependency-Schemas Ã¼bereinstimmen
4. **Richtige Datentypen**: Werte in Bedingungen mÃ¼ssen zum `output_range.type` der Dependency passen

**VerknÃ¼pfungsarten:**

```yaml
# 1. Gewichteter Durchschnitt (fÃ¼r QualitÃ¤tsmetriken)
rules:
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 0
    value: "weighted_average"
    weights:
      neutrality: 2.0
      factuality: 2.5
      pedagogy: 2.0
      # Summe der Gewichte muss nicht 1.0 sein
      # Wird automatisch normalisiert

# 2. UND-VerknÃ¼pfung (fÃ¼r Compliance)
rules:
  - conditions:
      - dimension: youth_protection_legal
        operator: "=="
        value: 1
      - dimension: legal_compliance
        operator: "=="
        value: 1
    value: 1
    label: "COMPLIANT"

# 3. ODER-VerknÃ¼pfung (mindestens eine Bedingung)
rules:
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 4
    value: 4.0
    label: "Exzellent in NeutralitÃ¤t"
  - conditions:
      - dimension: factuality
        operator: ">="
        value: 4
    value: 4.0
    label: "Exzellent in Sachrichtigkeit"

# 4. Hierarchische Regeln (erste passende Regel gewinnt)
rules:
  # Spezialfall: Niedrige Sachrichtigkeit â†’ Schlechte Bewertung
  - conditions:
      - dimension: factuality
        operator: "<"
        value: 2.0
    value: 1.0
    label: "Unzureichend"
  # Normalfall: Gewichteter Durchschnitt
  - conditions:
      - dimension: factuality
        operator: ">="
        value: 2.0
    value: "weighted_average"
    label: "Berechnet"

# 5. Summen-Aggregation (fÃ¼r Split-Schemas)
# Ideal fÃ¼r groÃŸe Schemas (z.B. 50 Items) in Teilschemas (z.B. 5Ã—10)
id: sachrichtigkeit_gesamt
dependencies:
  - sachrichtigkeit_teil1  # Items 1-10
  - sachrichtigkeit_teil2  # Items 11-20
  - sachrichtigkeit_teil3  # Items 21-30
  - sachrichtigkeit_teil4  # Items 31-40
  - sachrichtigkeit_teil5  # Items 41-50

rules:
  - conditions:
      - dimension: factuality_part1
        operator: ">="
        value: 0
    value: "sum"
    label: "Gesamtbewertung"
    reasoning: "Summe aller Teilbewertungen"

# Beispiel: 5 Teilschemas Ã  10 Punkte = max. 50 Punkte gesamt
output_range:
  min: 0.0
  max: 50.0
  type: float
```

**Split-Schema-Pattern fÃ¼r groÃŸe Bewertungen:**

GroÃŸe Schemas (>30 Items) kÃ¶nnen in kleinere Teilschemas aufgeteilt werden fÃ¼r:

1. **Performance-Optimierung**: Teilschemas werden parallel evaluiert
2. **Token-Limits**: Umgehung von LLM-Context-Limits
3. **ModularitÃ¤t**: Einfachere Wartung und Updates einzelner Teile
4. **Caching**: Teilschemas kÃ¶nnen separat gecacht werden

**Beispiel-Struktur:**
```
sachrichtigkeit_teil1.yaml (Items 1-10)   â†’ Score 0-10
sachrichtigkeit_teil2.yaml (Items 11-20)  â†’ Score 0-10
sachrichtigkeit_teil3.yaml (Items 21-30)  â†’ Score 0-10
sachrichtigkeit_teil4.yaml (Items 31-40)  â†’ Score 0-10
sachrichtigkeit_teil5.yaml (Items 41-50)  â†’ Score 0-10
    â†“
sachrichtigkeit_gesamt.yaml (Derived)     â†’ Score 0-50 (Summe)
```

**Vorteile:**
- âœ… **5Ã— schneller** durch Parallelisierung (5 Schemas gleichzeitig)
- âœ… Jedes Teilschema bleibt unter Token-Limits
- âœ… Fehler in einem Teil beeintrÃ¤chtigen andere nicht
- âœ… Einzelne Teile kÃ¶nnen aktualisiert werden ohne Gesamtschema zu Ã¤ndern

**Best Practices:**

- âœ… **AussagekrÃ¤ftige Labels**: Labels sollten den Zustand klar beschreiben
- âœ… **Fallback definieren**: Immer ein `default` fÃ¼r unerwartete FÃ¤lle
- âœ… **Confidence-Werte**: HÃ¶here confidence bei strengeren Bedingungen
- âœ… **Dokumentation**: `reasoning` sollte die Logik erklÃ¤ren
- âœ… **Split-Schemas**: Bei >30 Items in Teilschemas aufteilen
- âš ï¸ **Reihenfolge**: Spezifische Regeln vor allgemeinen Regeln
- âš ï¸ **Gewichte sinnvoll**: Wichtigere Dimensionen stÃ¤rker gewichten

**HÃ¤ufige Fehler vermeiden:**

```yaml
# âŒ FALSCH: Zirkelbezug
# overall_quality.yaml:
dependencies:
  - neutralitaet_old
  - overall_quality  # Fehler: Selbstreferenz!

# âŒ FALSCH: Falsche Dimension
dependencies:
  - neutralitaet_old  # dimension: neutrality
rules:
  - conditions:
      - dimension: neutralitaet  # Fehler: Muss "neutrality" sein!
        operator: ">="
        value: 3

# âŒ FALSCH: Typ-Mismatch
dependencies:
  - jugendschutz_gate  # output_range.type: int (0 oder 1)
rules:
  - conditions:
      - dimension: youth_protection_legal
        operator: ">="
        value: 0.5  # Fehler: Muss integer sein!

# âœ… RICHTIG: Korrekte VerknÃ¼pfung
dependencies:
  - jugendschutz_gate  # dimension: youth_protection_legal
rules:
  - conditions:
      - dimension: youth_protection_legal
        operator: "=="
        value: 1  # Korrekt: Integer-Wert
```

#### Metadata und Dokumentation

```yaml
# ZusÃ¤tzliche Metadaten
metadata:
  author: "QualitÃ¤tsteam"
  created: "2025-01-17"
  last_modified: "2025-01-17"
  review_cycle: "quarterly"
  
# Dokumentation fÃ¼r Entwickler
documentation:
  purpose: "Bewertung der NeutralitÃ¤t in Bildungsinhalten"
  methodology: "Anker-basierte Bewertung mit KI-UnterstÃ¼tzung"
  validation: "Getestet mit 100+ Beispieltexten"
  
# Konfiguration fÃ¼r KI-Bewertung
ai_config:
  model: "gpt-4"
  temperature: 0.1
  max_tokens: 500
  prompt_template: "Bewerte die NeutralitÃ¤t des folgenden Textes..."
```

### Validierung und Testing

#### Schema-Validierung

```bash
# YAML-Syntax prÃ¼fen
python -c "import yaml; yaml.safe_load(open('schemes/schema.yaml'))"

# Schema-Struktur validieren
python -m core.evaluation --validate-schema schemes/schema.yaml

# Alle Schemas validieren
python -m core.evaluation --validate-all
```

#### Test-Cases definieren

```yaml
# Optional: Test-Cases im Schema
test_cases:
  - input: "Neutral formulierter Text Ã¼ber Politik..."
    expected_value: 4
    expected_label: "Weitgehend neutral"
    
  - input: "Stark einseitiger Text..."
    expected_value: 1
    expected_label: "Einseitig"
```

### Best Practices fÃ¼r YAML-Schemas

#### 1. Naming Conventions
```yaml
# Schema-IDs: lowercase, underscore
id: sachrichtigkeit_new

# Dimensionen: englisch, lowercase
dimension: factuality

# Kriterien-IDs: deutsch, underscore
criteria:
  - id: faktentreue
  - id: quellenangaben
```

#### 2. Gewichtung
```yaml
# Wichtigste Kriterien: 2.0-2.5
# Normale Kriterien: 1.0-1.5
# ErgÃ¤nzende Kriterien: 0.5-1.0
weights:
  factuality: 2.5      # Sehr wichtig
  neutrality: 2.0      # Wichtig
  timeliness: 1.5      # Normal
  media_fit: 1.0       # ErgÃ¤nzend
```

#### 3. Confidence-Werte
```yaml
# Hohe Sicherheit: 0.9-1.0
# Mittlere Sicherheit: 0.7-0.8
# Niedrige Sicherheit: 0.5-0.6
confidence: 0.9
```

#### 4. Dokumentation
```yaml
# Immer aussagekrÃ¤ftige Beschreibungen
description: "Bewertung der faktischen Korrektheit und QuellenqualitÃ¤t"

# Konkrete Beispiele fÃ¼r Kriterien
examples:
  - "Zahlen sind durch seriÃ¶se Quellen belegt"
  - "Historische Fakten sind korrekt dargestellt"
```

## ğŸ”„ Derived Schemas - Kombinationslogik & Rekursion

### Rekursive Evaluation (Master-Gates)

Die API unterstÃ¼tzt **mehrstufige Derived-Schemas** fÃ¼r komplexe Evaluierungen:

```yaml
# Ebene 3: Master-Gate (kombiniert Sub-Gates)
id: criminal_law_gate
dependencies:
  - criminal_law_1a_gate  # Ebene 2: Sub-Gate
  - criminal_law_1b_gate  # Ebene 2: Sub-Gate

# Ebene 2: Sub-Gate (kombiniert Parts)
id: criminal_law_1a_gate
dependencies:
  - criminal_law_1a_part1  # Ebene 1: Part-Schema
  - criminal_law_1a_part2
  - criminal_law_1a_part3
  # ... bis part10

# Ebene 1: Part-Schema (eigentliche LLM-Evaluation)
id: criminal_law_1a_part1
type: binary_gate
gate_rules: [...]  # TatsÃ¤chliche PrÃ¼fkriterien
```

**Hierarchie:**
```
Master-Gate (Ebene 3)
  â†“ [parallel]
Sub-Gates (Ebene 2)
  â†“ [parallel]
Part-Schemas (Ebene 1)
  â†“ [parallel]
LLM-Calls
```

**Vorteile der Rekursion:**
- âœ… **Performance**: Alle Dependencies werden parallel evaluiert
- âœ… **ModularitÃ¤t**: Ã„nderungen auf einer Ebene beeinflussen hÃ¶here Ebenen nicht
- âœ… **Transparenz**: VollstÃ¤ndige Kriterien-Hierarchie in der Response
- âœ… **FlexibilitÃ¤t**: Master-Gates kÃ¶nnen granular (Sub-Gates) oder vollstÃ¤ndig (Master-Gate) abgefragt werden

**Beispiel-Aufruf:**

```json
// Master-Gate (empfohlen fÃ¼r Endnutzer)
{"schemes": ["criminal_law_gate"]}  
// â†’ Evaluiert automatisch 1A + 1B â†’ jeweils 10+8 Parts â†’ 200+ Indikatoren

// Sub-Gate (fÃ¼r granulare PrÃ¼fung)
{"schemes": ["criminal_law_1a_gate"]}  
// â†’ Nur Hard Illegal (1A) â†’ 10 Parts â†’ 49 Indikatoren

// Part-Schema (fÃ¼r Entwickler/Debugging)
{"schemes": ["criminal_law_1a_part1"]}  
// â†’ Nur Verfassungsfeindliche Symbole â†’ 5 Indikatoren
```

**Response-Struktur** (verschachtelt):

```json
{
  "scheme_id": "criminal_law_gate",
  "value": 2,  // LEGAL
  "criteria": {
    "criminal_law_1a_gate": {
      "value": 1,  // PASS
      "criteria": {
        "criminal_law_1a_part1": {
          "value": 1,  // PASS
          "criteria": {
            "aspekt_1": {"passed": true, "rule_id": "1A-01"},
            "aspekt_2": {"passed": true, "rule_id": "1A-02"}
          }
        }
      }
    },
    "criminal_law_1b_gate": {"value": 1}
  }
}
```

**Best Practice:**
- **Endnutzer**: Immer Master-Gates verwenden (`*_gate` ohne Zahl)
- **Entwickler**: Sub-Gates fÃ¼r spezifische Tests
- **Debugging**: Part-Schemas nur bei Fehlersuche

### UND-VerknÃ¼pfung (AND Logic)
```yaml
gate_logic: "AND"
```
Alle Bedingungen mÃ¼ssen erfÃ¼llt sein.

**Beispiel:** `rechtliche_unbedenklichkeit_derived.yaml`
- Alle 4 Gates mÃ¼ssen `true` sein
- Ein `false` fÃ¼hrt zur Gesamtablehnung

### ODER-VerknÃ¼pfung (OR Logic)
```yaml
gate_logic: "OR"
```
Mindestens eine Bedingung muss erfÃ¼llt sein.

### Gewichtete Kombination
```yaml
rules:
  - conditions: [...]
    value: "weighted_average"
    weights:
      neutrality: 2.0
      factuality: 2.5
      timeliness: 1.5
```

## ğŸ§ª Live-Tests & Swagger UI

**Interaktive API-Tests:** http://localhost:8001/docs

- âœ… **"Try it out" FunktionalitÃ¤t** fÃ¼r alle Endpoints
- âœ… **VollstÃ¤ndige Dokumentation** mit Beispielen
- âœ… **Schema-Validierung** und Error Handling
- âœ… **Echtzeit-Tests** direkt im Browser

## ğŸ“Š Praktische Beispiele

### Beispiel 1: VollstÃ¤ndige QualitÃ¤tsbewertung

**Anwendungsfall:** Bewertung von Bildungsinhalten vor VerÃ¶ffentlichung

```python
import httpx

# Request
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Die deutsche Wiedervereinigung war ein komplexer politischer Prozess, der 1989 mit dem Fall der Berliner Mauer begann. Verschiedene politische Akteure trugen zu diesem historischen Ereignis bei, darunter BÃ¼rgerbewegungen in der DDR, die Politik der Sowjetunion unter Gorbatschow und die diplomatischen BemÃ¼hungen der Bundesregierung.",
    "schemes": [
        "overall_quality",
        "rechtliche_compliance"
    ],
    "include_reasoning": true
})

# Response
result = response.json()
print(f"GesamtqualitÃ¤t: {result['results'][0]['value']}/5.0")
print(f"Rechtssicherheit: {'âœ“' if result['results'][1]['value'] == 1 else 'âœ—'}")
```

**Erwartete Ausgabe:**
```json
{
    "results": [
        {
            "scheme_id": "overall_quality",
            "value": 4.2,
            "label": "Gute QualitÃ¤t",
            "confidence": 0.88,
            "reasoning": "Der Text zeigt hohe Sachrichtigkeit und NeutralitÃ¤t...",
            "criteria": {
                "neutralitaet_old": {"value": 4, "label": "Weitgehend neutral"},
                "sachrichtigkeit_old": {"value": 5, "label": "VollstÃ¤ndig sachrichtig"},
                "aktualitaet_old": {"value": 4, "label": "Gut aktuell"}
            }
        },
        {
            "scheme_id": "rechtliche_compliance",
            "value": 1,
            "label": "PASS",
            "confidence": 0.95,
            "reasoning": "Alle rechtlichen PrÃ¼fungen bestanden"
        }
    ]
}
```

### Beispiel 2: Detaillierte QualitÃ¤tsprÃ¼fung

**Anwendungsfall:** Wissenschaftliche Artikel mit Fokus auf Faktentreue

```python
# Request fÃ¼r detaillierte Bewertung
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Laut einer Studie der UniversitÃ¤t MÃ¼nchen aus dem Jahr 2023 zeigen 78% der befragten SchÃ¼ler verbesserte Lernleistungen bei Verwendung digitaler Medien. Die Studie basiert auf einer Stichprobe von 1.200 SchÃ¼lern aus 15 bayerischen Gymnasien.",
    "schemes": [
        "sachrichtigkeit_new",
        "neutralitaet_new",
        "didaktik_methodik_new"
    ],
    "include_reasoning": true
})

# Detaillierte Kriterien-Analyse
for result in response.json()['results']:
    print(f"\n{result['scheme_id']}: {result['value']}/5.0")
    for criterion, details in result['criteria'].items():
        print(f"  - {criterion}: {details['value']} - {details['reasoning'][:50]}...")
```

### Beispiel 3: Compliance-SchnellprÃ¼fung

**Anwendungsfall:** User-Generated Content vor Freischaltung

```python
# Rechtliche SchnellprÃ¼fung
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Das ist ein normaler Kommentar zu einem Bildungsthema ohne problematische Inhalte.",
    "schemes": [
        "jugendschutz_gate",
        "strafrecht_gate",
        "persoenlichkeitsrechte_gate"
    ],
    "include_reasoning": false  # Schnelle PrÃ¼fung ohne Details
})

# Einfache Pass/Fail Auswertung
all_passed = all(r['value'] == 1 for r in response.json()['results'])
print(f"Content freigegeben: {'âœ“' if all_passed else 'âœ—'}")

# Detaillierte Fehleranalyse bei Problemen
if not all_passed:
    failed_gates = [r['scheme_id'] for r in response.json()['results'] if r['value'] == 0]
    print(f"Problematische Bereiche: {', '.join(failed_gates)}")
```

### Beispiel 4: Batch-Verarbeitung

**Anwendungsfall:** Bewertung mehrerer Inhalte

```python
import asyncio
import httpx

async def evaluate_content(client, text, schemes):
    """Einzelne Inhaltsbewertung"""
    response = await client.post("/evaluate", json={
        "text": text,
        "schemes": schemes,
        "include_reasoning": false
    })
    return response.json()

async def batch_evaluate():
    """Batch-Bewertung mehrerer Inhalte"""
    contents = [
        "Lerninhalt 1: Geschichte der Demokratie...",
        "Lerninhalt 2: Mathematische Grundlagen...",
        "Lerninhalt 3: Naturwissenschaftliche Experimente..."
    ]
    
    async with httpx.AsyncClient(base_url="http://localhost:8001") as client:
        tasks = [
            evaluate_content(client, content, ["overall_quality", "rechtliche_compliance"])
            for content in contents
        ]
        results = await asyncio.gather(*tasks)
    
    # Ergebnisse auswerten
    for i, result in enumerate(results):
        quality = result['results'][0]['value']
        compliance = result['results'][1]['value']
        print(f"Inhalt {i+1}: QualitÃ¤t {quality}/5.0, Compliance {'âœ“' if compliance else 'âœ—'}")

# AusfÃ¼hrung
asyncio.run(batch_evaluate())
```

### Beispiel 5: Error Handling

**Anwendungsfall:** Robuste Fehlerbehandlung

```python
import httpx
from typing import Dict, Any

def safe_evaluate(text: str, schemes: list) -> Dict[str, Any]:
    """Sichere Bewertung mit Fehlerbehandlung"""
    try:
        response = httpx.post(
            "http://localhost:8001/evaluate",
            json={
                "text": text,
                "schemes": schemes,
                "include_reasoning": true
            },
            timeout=30.0  # 30 Sekunden Timeout
        )
        response.raise_for_status()
        return {
            "success": True,
            "data": response.json()
        }
    
    except httpx.TimeoutException:
        return {
            "success": False,
            "error": "Timeout: Bewertung dauerte zu lange",
            "retry_recommended": True
        }
    
    except httpx.HTTPStatusError as e:
        return {
            "success": False,
            "error": f"HTTP {e.response.status_code}: {e.response.text}",
            "retry_recommended": e.response.status_code >= 500
        }
    
    except Exception as e:
        return {
            "success": False,
            "error": f"Unerwarteter Fehler: {str(e)}",
            "retry_recommended": False
        }

# Verwendung
result = safe_evaluate(
    "Beispieltext fÃ¼r Bewertung",
    ["neutralitaet_new", "sachrichtigkeit_new"]
)

if result["success"]:
    print("Bewertung erfolgreich:", result["data"])
else:
    print("Fehler:", result["error"])
    if result["retry_recommended"]:
        print("Wiederholung empfohlen")
```

## âš–ï¸ Deutsche RechtskonformitÃ¤t

### Abgedeckte Gesetze
- âœ… **Strafgesetzbuch (StGB)**: Volksverhetzung, Gewaltverherrlichung, Beleidigung
- âœ… **Jugendschutzgesetz (JuSchG)**: Altersgerechte Inhalte, Entwicklungsschutz
- âœ… **DSGVO**: Datenschutz, PersÃ¶nlichkeitsrechte
- âœ… **Kunsturhebergesetz (KUG)**: Bildrechte, Recht am eigenen Bild
- âœ… **NetzDG**: Strafbare Inhalte in sozialen Netzwerken
- âœ… **Digital Services Act (DSA)**: EU-Digitalrecht

### Automatische Risikobewertung
- ğŸ”´ **Critical**: Schwere Straftaten â†’ Sofortige Sperrung
- ğŸŸ  **High**: Erhebliche RechtsverstÃ¶ÃŸe â†’ Manuelle PrÃ¼fung
- ğŸŸ¡ **Medium**: Zivilrechtliche Folgen â†’ Ãœberarbeitung empfohlen
- ğŸŸ¢ **Low**: GeringfÃ¼gige VerstÃ¶ÃŸe â†’ Hinweis ausreichend

## ğŸ¯ Best Practices

### Schema-Auswahl fÃ¼r verschiedene AnwendungsfÃ¤lle

#### ğŸ“š **Bildungsinhalte (Empfohlen)**
```json
{"schemes": ["overall_quality", "rechtliche_compliance"]}
```

#### ğŸ‘¥ **User-Generated Content**
```json
{"schemes": ["jugendschutz_gate", "strafrecht_gate", "persoenlichkeitsrechte_gate"]}
```

#### ğŸ”¬ **Wissenschaftliche Texte**
```json
{"schemes": ["sachrichtigkeit_new", "neutralitaet_new"]}
```

#### âš¡ **Schnelle QualitÃ¤tsprÃ¼fung**
```json
{"schemes": ["neutralitaet_old", "sachrichtigkeit_old"], "include_reasoning": false}
```

### Performance & ZuverlÃ¤ssigkeit
- âœ… **Automatische Fehlerbehandlung** fÃ¼r ungÃ¼ltige Schema-IDs
- âœ… **Timeout-Protection** fÃ¼r KI-Bewertungen
- âœ… **Dependency-Validation** fÃ¼r derived Schemas
- âœ… **Rate Limiting** berÃ¼cksichtigen (OpenAI API)
- âœ… **Retry-Logic** fÃ¼r temporÃ¤re Fehler

## ğŸ”§ Entwicklung & Erweiterung

### API Status & Monitoring
```bash
# API Health Check
curl http://localhost:8001/health

# Alle verfÃ¼gbaren Schemas auflisten
curl http://localhost:8001/schemes

# Test-Bewertung durchfÃ¼hren
curl -X POST http://localhost:8001/evaluate \
  -H "Content-Type: application/json" \
  -d '{"text":"Testinhalt", "schemes":["neutralitaet_old"]}'
```

### Neues Schema erstellen
1. YAML-Datei in `schemes/` erstellen
2. Schema-Typ und Parameter definieren
3. Kriterien und Regeln spezifizieren
4. API neu starten fÃ¼r automatisches Laden

### Debugging & Logs
- âœ… **Structured Logging** mit Loguru
- âœ… **Request/Response Tracing**
- âœ… **Error Details** in API Responses
- âœ… **Schema Loading Status** beim Startup

## ğŸ“ˆ Produktionsstatus

### âœ… FunktionsfÃ¤hige Features
- ğŸŸ¢ **API Server**: LÃ¤uft stabil auf Port 8001
- ğŸŸ¢ **Alle Endpoints**: Health, Schemes, Evaluate funktionsfÃ¤hig
- ğŸŸ¢ **15 Bewertungsschemas**: VollstÃ¤ndig geladen und getestet
- ğŸŸ¢ **KI-Integration**: OpenAI GPT-4 Bewertungen
- ğŸŸ¢ **Swagger UI**: VollstÃ¤ndige interaktive Dokumentation
- ğŸŸ¢ **Error Handling**: Robuste Fehlerbehandlung
- ğŸŸ¢ **Schema Validation**: Pydantic-basierte Validierung

### ğŸ”„ Letzte Updates (2025-01-18)
- âœ… Fixed Swagger UI "Try it out" FunktionalitÃ¤t
- âœ… Erweiterte API-Dokumentation mit Beispielen
- âœ… Verbesserte Schema-Validierung fÃ¼r Binary Gates
- âœ… Dependency Injection KompatibilitÃ¤t

## ğŸ“ Lizenz & Rechtliches

Dieses System implementiert deutsche Rechtsstandards und ist fÃ¼r den Einsatz in Deutschland optimiert. Bei internationaler Nutzung sind lokale Gesetze zu beachten.

**âš ï¸ Haftungsausschluss**: Die automatische RechtsprÃ¼fung ersetzt keine juristische Beratung. Bei kritischen Inhalten sollte immer eine manuelle PrÃ¼fung erfolgen.

---

**ğŸš€ Ready for Production** | **ğŸ¤– LLM as Judge** | **ğŸ“š Full Documentation** | **ğŸ”§ Easy to Extend**
