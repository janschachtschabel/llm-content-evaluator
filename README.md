# LLM Content Evaluator - KI-gestÃ¼tzte Inhaltsbewertung

ğŸ¯ **Produktive FastAPI-Anwendung** mit **LLM as Judge** Methodologie zur automatisierten Bewertung von Bildungsinhalten mit KI-gestÃ¼tzter Analyse, deutschen Rechtsstandards und pÃ¤dagogischen QualitÃ¤tskriterien.

## ğŸš€ Features

- âœ… **17 Bewertungsschemas** fÃ¼r umfassende QualitÃ¤tsprÃ¼fung
- âœ… **4 Schema-Typen**: Ordinal, Checklist, Binary Gates, Derived
- âœ… **LLM as Judge Methodologie** mit OpenAI GPT-4 Integration
- âœ… **Deutsche RechtskonformitÃ¤t**: StGB, DSGVO, JuSchG, PersÃ¶nlichkeitsrechte
- âœ… **PÃ¤dagogische QualitÃ¤t**: Didaktik, NeutralitÃ¤t, Sachrichtigkeit, AktualitÃ¤t
- âœ… **RESTful API** mit vollstÃ¤ndiger OpenAPI/Swagger Dokumentation
- âœ… **Produktionsbereit** mit Error Handling und Validation
- âœ… **Flexible Ausgabe**: Detaillierte BegrÃ¼ndungen und Kriterien-Breakdown

## ğŸ“‹ Ãœbersicht aller Schemas

### QualitÃ¤tsbewertung (13 Schemas)

| Schema ID | Typ | Beschreibung | Skala | Kriterien |
|-----------|-----|--------------|-------|-----------|
| `sachrichtigkeit_new` | Checklist | Detaillierte Sachrichtigkeit | 10 Kriterien | Faktentreue, Quellenangaben, Wissenschaftlichkeit |
| `neutralitaet_new` | Checklist | Detaillierte NeutralitÃ¤t | 10 Kriterien | Ausgewogenheit, ObjektivitÃ¤t, Meinungsvielfalt |
| `aktualitaet_new` | Checklist | Detaillierte AktualitÃ¤t | 10 Kriterien | ZeitgemÃ¤ÃŸheit, Relevanz, Updates |
| `didaktik_methodik_new` | Checklist | Detaillierte Didaktik | 10 Kriterien | Lernziele, Methoden, VerstÃ¤ndlichkeit |
| `sprachliche_angemessenheit_new` | Checklist | Detaillierte Sprache | 10 Kriterien | VerstÃ¤ndlichkeit, Stil, Zielgruppe, Grammatik |
| `medial_passend_new` | Checklist | Detaillierte Mediale Passung | 10 Kriterien | Technische QualitÃ¤t, InteraktivitÃ¤t, ZugÃ¤nglichkeit |
| `sachrichtigkeit_old` | Ordinal | Sachrichtigkeit (0-5) | 6 Stufen | Kompakte Bewertung der Faktentreue |
| `neutralitaet_old` | Ordinal | NeutralitÃ¤t (0-5) | 6 Stufen | Kompakte Bewertung der Ausgewogenheit |
| `aktualitaet_old` | Ordinal | AktualitÃ¤t (0-5) | 6 Stufen | Kompakte Bewertung der ZeitgemÃ¤ÃŸheit |
| `sprachliche_angemessenheit_old` | Ordinal | Sprache (0-5) | 6 Stufen | VerstÃ¤ndlichkeit, Stil, Zielgruppe |
| `didaktik_methodik_old` | Ordinal | Didaktik (0-5) | 6 Stufen | Kompakte pÃ¤dagogische Bewertung |
| `medial_passend_old` | Ordinal | Mediale Passung (0-5) | 6 Stufen | Medieneignung, Darstellung |
| `overall_quality` | Derived | GesamtqualitÃ¤t | 0.0-5.0 | Gewichtete Kombination aller Dimensionen |

### Compliance & Rechtssicherheit (4 Schemas)

| Schema ID | Typ | Beschreibung | Rechtsbasis | PrÃ¼fbereiche |
|-----------|-----|--------------|-------------|--------------|
| `jugendschutz_gate` | Binary Gate | Jugendschutz | JuSchG, JMStV | Altersgerechte Inhalte, Entwicklungsschutz |
| `strafrecht_gate` | Binary Gate | Strafrecht | StGB, NetzDG | Volksverhetzung, Gewaltverherrlichung |
| `persoenlichkeitsrechte_gate` | Binary Gate | PersÃ¶nlichkeitsrechte | DSGVO, KUG | Bildrechte, Datenschutz, PrivatsphÃ¤re |
| `rechtliche_compliance` | Derived | Rechtliche Gesamtbewertung | Alle Gates | UND-VerknÃ¼pfung aller Compliance-Gates |

## ğŸ› ï¸ Installation & Setup

### Voraussetzungen
- Python 3.8+
- OpenAI API Key (fÃ¼r KI-basierte Bewertung)
- FastAPI, Uvicorn, Pydantic (automatisch installiert)

### Schnellstart

```bash
# Repository klonen
git clone <repository-url>
cd api-scoring-quality/api-eval-25

# Umgebung einrichten
cp .env.example .env
# .env mit OpenAI API Key bearbeiten:
# OPENAI_API_KEY=your_api_key_here

# Dependencies installieren
pip install fastapi uvicorn openai pydantic loguru pyyaml

# Server starten
python main.py
```

ğŸŒ **Server lÃ¤uft auf: http://localhost:8001**  
ğŸ“š **API Dokumentation: http://localhost:8001/docs**  
ğŸ” **Alternative Docs: http://localhost:8001/redoc**

## ğŸ”— API Endpoints

### ğŸ¥ Health Check
```http
GET /health
```
**Status:** âœ… FunktionsfÃ¤hig  
**Zweck:** API-Status und geladene Schemas prÃ¼fen

### ğŸ“‹ Schema-Ãœbersicht  
```http
GET /schemes
```
**Status:** âœ… FunktionsfÃ¤hig  
**Zweck:** Alle 15 verfÃ¼gbaren Bewertungsschemas auflisten

### ğŸ¯ Text-Bewertung
```http
POST /evaluate
```
**Status:** âœ… FunktionsfÃ¤hig  
**Zweck:** KI-gestÃ¼tzte Bewertung von Bildungsinhalten

**Beispiel-Request:**
```json
{
    "text": "Die deutsche Wiedervereinigung war ein komplexer politischer Prozess...",
    "schemes": ["neutralitaet_new", "sachrichtigkeit_old", "rechtliche_compliance"],
    "include_reasoning": true
}
```

**Beispiel-Response:**
```json
{
    "results": [
        {
            "scheme_id": "neutralitaet_new",
            "value": 4.2,
            "label": "Weitgehend neutral",
            "confidence": 0.88,
            "reasoning": "Der Text stellt verschiedene Perspektiven ausgewogen dar...",
            "criteria": {
                "ausgewogenheit": {"value": 4, "reasoning": "Mehrere Standpunkte berÃ¼cksichtigt"},
                "objektivitaet": {"value": 4, "reasoning": "Sachliche Darstellung ohne Wertungen"}
            }
        }
    ],
    "gates_passed": true,
    "metadata": {
        "processing_time_ms": 1250,
        "model_used": "gpt-4"
    }
}
```

## ğŸ“– YAML Schema-Parameter - Detaillierte Anleitung

### Grundstruktur aller Schemas

Jedes YAML-Schema folgt einer einheitlichen Grundstruktur:

```yaml
# Eindeutige Identifikation
id: schema_identifier
name: "Benutzerfreundlicher Anzeigename"
description: "Detaillierte Beschreibung des Bewertungszwecks"
dimension: dimension_name  # Technischer Dimensionsname
type: ordinal|checklist|binary_gate|derived
version: "1.0"

# Ausgabeformat definieren
output_range:
  min: 0      # Minimaler Wert
  max: 5      # Maximaler Wert  
  type: int   # int, float oder boolean
  values: [0, 1, 2, 3, 4, 5]  # Optional: Erlaubte Werte
```

**Pflichtfelder:**
- `id`: Eindeutige Schema-ID (keine Leerzeichen, Kleinbuchstaben)
- `name`: Anzeigename fÃ¼r BenutzeroberflÃ¤che
- `type`: Schema-Typ bestimmt Bewertungslogik
- `output_range`: Definiert mÃ¶gliche Ausgabewerte

### Schema-Typen im Detail

#### 1. Ordinal Schema - Anker-basierte Bewertung (0-5 Skala)

Ordinal-Schemas verwenden vordefinierte Anker fÃ¼r konsistente Bewertungen:

```yaml
id: neutralitaet_old
name: "NeutralitÃ¤t (Ordinal)"
description: "Bewertung der politischen und weltanschaulichen NeutralitÃ¤t"
dimension: neutrality
type: ordinal
version: "1.0"

output_range:
  min: 0
  max: 5
  type: int

# Bewertungsstrategie
strategy: first_match  # oder best_fit

# Anker in absteigender Reihenfolge (5 â†’ 0)
anchors:
  - value: 5
    label: "VollstÃ¤ndig neutral"
    criteria: |
      - Alle Standpunkte werden fair dargestellt
      - Keine erkennbare politische Tendenz
      - Ausgewogene Quellenauswahl
      - Objektive Sprache durchgehend
      
  - value: 4
    label: "Weitgehend neutral"
    criteria: |
      - Ãœberwiegend ausgewogene Darstellung
      - Minimale Tendenz erkennbar
      - Verschiedene Perspektiven berÃ¼cksichtigt
      
  - value: 3
    label: "Teilweise neutral"
    criteria: |
      - GrundsÃ¤tzlich um NeutralitÃ¤t bemÃ¼ht
      - Deutliche Tendenz in eine Richtung
      - Nicht alle Standpunkte gleichwertig dargestellt
      
  - value: 2
    label: "Wenig neutral"
    criteria: |
      - Starke Tendenz erkennbar
      - Einseitige Quellenauswahl
      - Gegenpositionen nur oberflÃ¤chlich behandelt
      
  - value: 1
    label: "Einseitig"
    criteria: |
      - Deutlich parteiische Darstellung
      - Wichtige Gegenpositionen fehlen
      - Wertende Sprache dominiert
      
  - value: 0
    label: "Stark einseitig"
    criteria: |
      - Propagandistische Darstellung
      - Keine BerÃ¼cksichtigung anderer Standpunkte
      - Manipulative oder hetzerische Sprache

# Fallback bei unklaren FÃ¤llen
default:
  value: 0
  label: "Unbewertet"
  reasoning: "Keine ausreichenden Informationen fÃ¼r Bewertung"
  confidence: 0.0

# ZusÃ¤tzliche Metadaten
labels:
  "5": "Exzellent neutral"
  "4": "Gut neutral"
  "3": "Akzeptabel"
  "2": "VerbesserungsbedÃ¼rftig"
  "1": "Problematisch"
  "0": "Inakzeptabel"
```

**Strategien:**
- `first_match`: Erste passende Bewertung wird verwendet
- `best_fit`: Beste Ãœbereinstimmung wird gesucht

**VollstÃ¤ndiges Beispiel:** `neutralitaet_old.yaml`

#### 2. Checklist Schema - Kriterien-basierte Bewertung

Checklist-Schemas bewerten anhand gewichteter Einzelkriterien mit **kompakter Strukturbeschreibung**:

```yaml
id: sachrichtigkeit_new
name: "Sachrichtigkeit (Detailliert)"
description: "Umfassende Bewertung der faktischen Korrektheit"
dimension: factuality
type: checklist_additive
version: "1.0"

output_range:
  min: 0.0
  max: 5.0
  type: float

# Einzelkriterien mit strukturierten Werten (NEUE KOMPAKTE STRUKTUR)
items:
  - id: faktentreue
    prompt: "Sind alle Fakten und Aussagen korrekt und verifizierbar?"
    weight: 2.5
    values:
      1: {score: 0.25, description: "Viele falsche oder ungeprÃ¼fte Aussagen"}
      2: {score: 0.5, description: "Einige faktische Fehler oder Ungenauigkeiten"}
      3: {score: 0.75, description: "Ãœberwiegend korrekte Fakten, wenige Fehler"}
      4: {score: 1.0, description: "Alle Fakten korrekt und gut verifizierbar"}
      na: null
      
  - id: quellenangaben
    prompt: "Sind alle Behauptungen mit seriÃ¶sen Quellen belegt?"
    weight: 2.0
    values:
      1: {score: 0.25, description: "Keine oder unzuverlÃ¤ssige Quellenangaben"}
      2: {score: 0.5, description: "Wenige oder teilweise fragwÃ¼rdige Quellen"}
      3: {score: 0.75, description: "Gute Quellenangaben, meist seriÃ¶s"}
      4: {score: 1.0, description: "VollstÃ¤ndige, seriÃ¶se und aktuelle Quellenangaben"}
      na: null

# Aggregation mit gewichtetem Mittelwert
aggregator:
  strategy: weighted_mean
  params:
    missing: ignore
    scale_factor: 5.0  # Skaliert von 0-1 auf 0-5

# Labels fÃ¼r Ausgabe
labels:
  "0.0": "Unzureichend"
  "1.0": "Mangelhaft"
  "2.0": "Ausreichend"
  "3.0": "Befriedigend"
  "4.0": "Gut"
  "5.0": "Sehr gut"
```

**Neue Kompakte Struktur:**
- **Strukturierte Werte:** `{score: 0.25, description: "..."}` statt einfacher Kommentare
- **Bessere LLM-Prompts:** Beschreibungen werden direkt in Bewertungsprompts eingebunden
- **Einheitliche Skalierung:** Alle Kriterien verwenden 1-4 Level mit 0.25-1.0 Scores

**VollstÃ¤ndiges Beispiel:** `sachrichtigkeit_new.yaml`, `neutralitaet_new.yaml`, `sprachliche_angemessenheit_new.yaml`, `medial_passend_new.yaml`

#### 3. Binary Gate - Pass/Fail Bewertung

Binary Gates sind K.O.-Kriterien fÃ¼r Compliance-PrÃ¼fungen:

```yaml
id: strafrecht_gate
name: "Strafrechtliche Unbedenklichkeit"
description: "PrÃ¼fung auf VerstÃ¶ÃŸe gegen deutsches Strafrecht"
dimension: legal_compliance
type: binary_gate
version: "1.0"

output_range:
  values: [true, false]
  type: boolean

# PrÃ¼fkriterien (wird in criteria-Feld dokumentiert)
criteria: |
  Automatische PrÃ¼fung auf strafrechtlich relevante Inhalte:
  - Volksverhetzung (Â§ 130 StGB)
  - Gewaltverherrlichung (Â§ 131 StGB)
  - Beleidigung und Verleumdung (Â§ 185-187 StGB)
  - Bedrohung (Â§ 241 StGB)
  - Verfassungswidrige Symbole (Â§ 86a StGB)

# Gate-Regeln (Reihenfolge wichtig!)
gate_rules:
  - condition: "volksverhetzung"
    action: reject
    reason: "Inhalt enthÃ¤lt volksverhetzende Ã„uÃŸerungen (Â§ 130 StGB)"
    severity: critical
    legal_reference: "Â§ 130 StGB"
    confidence: 0.9
    
  - condition: "gewaltverherrlichung"
    action: reject
    reason: "Inhalt verherrlicht Gewalt (Â§ 131 StGB)"
    severity: critical
    legal_reference: "Â§ 131 StGB"
    confidence: 0.85
    
  - condition: "beleidigung"
    action: reject
    reason: "Inhalt enthÃ¤lt Beleidigungen (Â§ 185-187 StGB)"
    severity: medium
    legal_reference: "Â§ 185-187 StGB"
    confidence: 0.7
    
  - condition: "bedrohung"
    action: reject
    reason: "Inhalt enthÃ¤lt Bedrohungen (Â§ 241 StGB)"
    severity: high
    legal_reference: "Â§ 241 StGB"
    confidence: 0.8

# Standard-Aktion wenn keine Regel greift
default_action: pass

# Automatische Keyword-Erkennung
detection_patterns:
  volksverhetzung:
    - "holocaustleugnung"
    - "rassenhass"
    - "judenhass"
    - "auslÃ¤nder raus"
    - "vernichtung"
    
  gewaltverherrlichung:
    - "folter verherrlichen"
    - "gewalt glorifizieren"
    - "hinrichtung feiern"
    - "sadismus"
    
  beleidigung:
    - "idiot"
    - "schwachkopf"
    - "versager"
    # (Kontext-abhÃ¤ngig)
    
  bedrohung:
    - "ich bringe dich um"
    - "du bist tot"
    - "warte nur ab"

# Severity-Level Definitionen
severity_levels:
  critical: "Schwere Straftaten mit GefÃ¤ngnisstrafe"
  high: "Straftaten mit erheblicher gesellschaftlicher Relevanz"
  medium: "RechtsverstÃ¶ÃŸe mit zivilrechtlichen Konsequenzen"
  low: "GeringfÃ¼gige RechtsverstÃ¶ÃŸe"

# Compliance-Referenzen
compliance_references:
  - "Strafgesetzbuch (StGB)"
  - "Netzwerkdurchsetzungsgesetz (NetzDG)"
  - "Digital Services Act (DSA)"
```

**Gate-Logik:**
1. Regeln werden in Reihenfolge geprÃ¼ft
2. Erste zutreffende Regel bestimmt Ergebnis
3. Bei keiner Regel: `default_action`

**Severity-Levels:**
- `critical`: Sofortige Sperrung erforderlich
- `high`: Manuelle PrÃ¼fung erforderlich
- `medium`: Warnung an Nutzer
- `low`: Hinweis ausreichend

**VollstÃ¤ndiges Beispiel:** `strafrecht_gate.yaml`

#### 4. Derived Schema - Kombination anderer Schemas

Derived Schemas kombinieren Ergebnisse anderer Schemas:

```yaml
id: overall_quality
name: "GesamtqualitÃ¤t"
description: "Gewichtete Kombination aller QualitÃ¤tsdimensionen"
dimension: overall_quality
type: derived
version: "2.0"

output_range:
  min: 0.0
  max: 5.0
  type: float

# AbhÃ¤ngigkeiten (mÃ¼ssen vorher ausgewertet werden)
dependencies:
  - neutralitaet_old
  - aktualitaet_old
  - sachrichtigkeit_old
  - sprachliche_angemessenheit_old
  - didaktik_methodik_old
  - medial_passend_old

# Kombinationsregeln
rules:
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 0
      - dimension: factuality
        operator: ">="
        value: 0
    value: "weighted_average"
    label: "Gewichtete Gesamtbewertung"
    reasoning: "Berechnung basierend auf gewichteten Einzeldimensionen"
    confidence: 0.9
    
    # Gewichtung der Dimensionen
    weights:
      neutrality: 2.0              # NeutralitÃ¤t (wichtig)
      timeliness: 1.5              # AktualitÃ¤t
      factuality: 2.5              # Sachrichtigkeit (sehr wichtig)
      language_appropriateness: 1.5 # Sprachliche Angemessenheit
      pedagogy: 2.0                # Didaktik/Methodik (wichtig)
      media_appropriateness: 1.0    # Mediale Passung
      
  # Spezialregel fÃ¼r niedrige Sachrichtigkeit
  - conditions:
      - dimension: factuality
        operator: "<"
        value: 2.0
    value: 1.0
    label: "Unzureichende Sachrichtigkeit"
    reasoning: "Niedrige Sachrichtigkeit fÃ¼hrt zu schlechter Gesamtbewertung"
    confidence: 0.95

# Fallback
default:
  value: 0.0
  label: "Unbewertet"
  reasoning: "Keine ausreichenden Daten fÃ¼r Gesamtbewertung"
  confidence: 0.0

# Ausgabe-Labels
labels:
  "4.5-5.0": "Exzellente QualitÃ¤t"
  "3.5-4.4": "Gute QualitÃ¤t"
  "2.5-3.4": "Akzeptable QualitÃ¤t"
  "1.5-2.4": "VerbesserungsbedÃ¼rftig"
  "0.0-1.4": "Unzureichende QualitÃ¤t"

# Mathematische Operationen
calculation_method: weighted_average
normalization: true
```

**Kombinationslogik:**
- `weighted_average`: Gewichteter Durchschnitt
- `min`: Minimum aller Werte
- `max`: Maximum aller Werte
- `and_gate`: Alle mÃ¼ssen TRUE sein
- `or_gate`: Mindestens einer TRUE

**Operatoren fÃ¼r Bedingungen:**
- `==`: Gleich
- `!=`: Ungleich
- `>`: GrÃ¶ÃŸer
- `>=`: GrÃ¶ÃŸer oder gleich
- `<`: Kleiner
- `<=`: Kleiner oder gleich
- `in`: Wert in Liste
- `not_in`: Wert nicht in Liste

**VollstÃ¤ndiges Beispiel:** `overall_quality.yaml`

### Erweiterte YAML-Features

#### Conditional Logic (Bedingte Logik)

```yaml
rules:
  # Mehrere Bedingungen (UND-verknÃ¼pft)
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 3
      - dimension: factuality
        operator: ">="
        value: 4
    value: 4.5
    label: "Hohe QualitÃ¤t"
    
  # ODER-VerknÃ¼pfung mit condition_logic
  - condition_logic: "OR"
    conditions:
      - dimension: neutrality
        operator: "=="
        value: 5
      - dimension: factuality
        operator: "=="
        value: 5
    value: 4.0
    label: "Exzellenz in einer Dimension"
```

#### Gate Logic fÃ¼r Binary Schemas

```yaml
# UND-VerknÃ¼pfung (alle Gates mÃ¼ssen TRUE sein)
gate_logic: "AND"

# ODER-VerknÃ¼pfung (mindestens ein Gate TRUE)
gate_logic: "OR"

# Beispiel: Rechtliche Unbedenklichkeit
dependencies:
  - content_gate
  - jugendschutz_gate
  - strafrecht_gate
  - persoenlichkeitsrechte_gate

rules:
  - conditions:
      - dimension: content_safety
        operator: "=="
        value: true
      - dimension: youth_protection
        operator: "=="
        value: true
      - dimension: legal_compliance
        operator: "=="
        value: true
      - dimension: personality_rights
        operator: "=="
        value: true
    value: true
    label: "Rechtlich unbedenklich"
```

#### Metadata und Dokumentation

```yaml
# ZusÃ¤tzliche Metadaten
metadata:
  author: "QualitÃ¤tsteam"
  created: "2025-01-17"
  last_modified: "2025-01-17"
  review_cycle: "quarterly"
  
# Dokumentation fÃ¼r Entwickler
documentation:
  purpose: "Bewertung der NeutralitÃ¤t in Bildungsinhalten"
  methodology: "Anker-basierte Bewertung mit KI-UnterstÃ¼tzung"
  validation: "Getestet mit 100+ Beispieltexten"
  
# Konfiguration fÃ¼r KI-Bewertung
ai_config:
  model: "gpt-4"
  temperature: 0.1
  max_tokens: 500
  prompt_template: "Bewerte die NeutralitÃ¤t des folgenden Textes..."
```

### Validierung und Testing

#### Schema-Validierung

```bash
# YAML-Syntax prÃ¼fen
python -c "import yaml; yaml.safe_load(open('schemes/schema.yaml'))"

# Schema-Struktur validieren
python -m core.evaluation --validate-schema schemes/schema.yaml

# Alle Schemas validieren
python -m core.evaluation --validate-all
```

#### Test-Cases definieren

```yaml
# Optional: Test-Cases im Schema
test_cases:
  - input: "Neutral formulierter Text Ã¼ber Politik..."
    expected_value: 4
    expected_label: "Weitgehend neutral"
    
  - input: "Stark einseitiger Text..."
    expected_value: 1
    expected_label: "Einseitig"
```

### Best Practices fÃ¼r YAML-Schemas

#### 1. Naming Conventions
```yaml
# Schema-IDs: lowercase, underscore
id: sachrichtigkeit_new

# Dimensionen: englisch, lowercase
dimension: factuality

# Kriterien-IDs: deutsch, underscore
criteria:
  - id: faktentreue
  - id: quellenangaben
```

#### 2. Gewichtung
```yaml
# Wichtigste Kriterien: 2.0-2.5
# Normale Kriterien: 1.0-1.5
# ErgÃ¤nzende Kriterien: 0.5-1.0
weights:
  factuality: 2.5      # Sehr wichtig
  neutrality: 2.0      # Wichtig
  timeliness: 1.5      # Normal
  media_fit: 1.0       # ErgÃ¤nzend
```

#### 3. Confidence-Werte
```yaml
# Hohe Sicherheit: 0.9-1.0
# Mittlere Sicherheit: 0.7-0.8
# Niedrige Sicherheit: 0.5-0.6
confidence: 0.9
```

#### 4. Dokumentation
```yaml
# Immer aussagekrÃ¤ftige Beschreibungen
description: "Bewertung der faktischen Korrektheit und QuellenqualitÃ¤t"

# Konkrete Beispiele fÃ¼r Kriterien
examples:
  - "Zahlen sind durch seriÃ¶se Quellen belegt"
  - "Historische Fakten sind korrekt dargestellt"
```

## ğŸ”„ Derived Schemas - Kombinationslogik

### UND-VerknÃ¼pfung (AND Logic)
```yaml
gate_logic: "AND"
```
Alle Bedingungen mÃ¼ssen erfÃ¼llt sein.

**Beispiel:** `rechtliche_unbedenklichkeit_derived.yaml`
- Alle 4 Gates mÃ¼ssen `true` sein
- Ein `false` fÃ¼hrt zur Gesamtablehnung

### ODER-VerknÃ¼pfung (OR Logic)
```yaml
gate_logic: "OR"
```
Mindestens eine Bedingung muss erfÃ¼llt sein.

### Gewichtete Kombination
```yaml
rules:
  - conditions: [...]
    value: "weighted_average"
    weights:
      neutrality: 2.0
      factuality: 2.5
      timeliness: 1.5
```

## ğŸ§ª Live-Tests & Swagger UI

**Interaktive API-Tests:** http://localhost:8001/docs

- âœ… **"Try it out" FunktionalitÃ¤t** fÃ¼r alle Endpoints
- âœ… **VollstÃ¤ndige Dokumentation** mit Beispielen
- âœ… **Schema-Validierung** und Error Handling
- âœ… **Echtzeit-Tests** direkt im Browser

## ğŸ“Š Praktische Beispiele

### Beispiel 1: VollstÃ¤ndige QualitÃ¤tsbewertung

**Anwendungsfall:** Bewertung von Bildungsinhalten vor VerÃ¶ffentlichung

```python
import httpx

# Request
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Die deutsche Wiedervereinigung war ein komplexer politischer Prozess, der 1989 mit dem Fall der Berliner Mauer begann. Verschiedene politische Akteure trugen zu diesem historischen Ereignis bei, darunter BÃ¼rgerbewegungen in der DDR, die Politik der Sowjetunion unter Gorbatschow und die diplomatischen BemÃ¼hungen der Bundesregierung.",
    "schemes": [
        "overall_quality",
        "rechtliche_compliance"
    ],
    "include_reasoning": true
})

# Response
result = response.json()
print(f"GesamtqualitÃ¤t: {result['results'][0]['value']}/5.0")
print(f"Rechtssicherheit: {'âœ“' if result['results'][1]['value'] == 1 else 'âœ—'}")
```

**Erwartete Ausgabe:**
```json
{
    "results": [
        {
            "scheme_id": "overall_quality",
            "value": 4.2,
            "label": "Gute QualitÃ¤t",
            "confidence": 0.88,
            "reasoning": "Der Text zeigt hohe Sachrichtigkeit und NeutralitÃ¤t...",
            "criteria": {
                "neutralitaet_old": {"value": 4, "label": "Weitgehend neutral"},
                "sachrichtigkeit_old": {"value": 5, "label": "VollstÃ¤ndig sachrichtig"},
                "aktualitaet_old": {"value": 4, "label": "Gut aktuell"}
            }
        },
        {
            "scheme_id": "rechtliche_compliance",
            "value": 1,
            "label": "PASS",
            "confidence": 0.95,
            "reasoning": "Alle rechtlichen PrÃ¼fungen bestanden"
        }
    ]
}
```

### Beispiel 2: Detaillierte QualitÃ¤tsprÃ¼fung

**Anwendungsfall:** Wissenschaftliche Artikel mit Fokus auf Faktentreue

```python
# Request fÃ¼r detaillierte Bewertung
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Laut einer Studie der UniversitÃ¤t MÃ¼nchen aus dem Jahr 2023 zeigen 78% der befragten SchÃ¼ler verbesserte Lernleistungen bei Verwendung digitaler Medien. Die Studie basiert auf einer Stichprobe von 1.200 SchÃ¼lern aus 15 bayerischen Gymnasien.",
    "schemes": [
        "sachrichtigkeit_new",
        "neutralitaet_new",
        "didaktik_methodik_new"
    ],
    "include_reasoning": true
})

# Detaillierte Kriterien-Analyse
for result in response.json()['results']:
    print(f"\n{result['scheme_id']}: {result['value']}/5.0")
    for criterion, details in result['criteria'].items():
        print(f"  - {criterion}: {details['value']} - {details['reasoning'][:50]}...")
```

### Beispiel 3: Compliance-SchnellprÃ¼fung

**Anwendungsfall:** User-Generated Content vor Freischaltung

```python
# Rechtliche SchnellprÃ¼fung
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Das ist ein normaler Kommentar zu einem Bildungsthema ohne problematische Inhalte.",
    "schemes": [
        "jugendschutz_gate",
        "strafrecht_gate",
        "persoenlichkeitsrechte_gate"
    ],
    "include_reasoning": false  # Schnelle PrÃ¼fung ohne Details
})

# Einfache Pass/Fail Auswertung
all_passed = all(r['value'] == 1 for r in response.json()['results'])
print(f"Content freigegeben: {'âœ“' if all_passed else 'âœ—'}")

# Detaillierte Fehleranalyse bei Problemen
if not all_passed:
    failed_gates = [r['scheme_id'] for r in response.json()['results'] if r['value'] == 0]
    print(f"Problematische Bereiche: {', '.join(failed_gates)}")
```

### Beispiel 4: Batch-Verarbeitung

**Anwendungsfall:** Bewertung mehrerer Inhalte

```python
import asyncio
import httpx

async def evaluate_content(client, text, schemes):
    """Einzelne Inhaltsbewertung"""
    response = await client.post("/evaluate", json={
        "text": text,
        "schemes": schemes,
        "include_reasoning": false
    })
    return response.json()

async def batch_evaluate():
    """Batch-Bewertung mehrerer Inhalte"""
    contents = [
        "Lerninhalt 1: Geschichte der Demokratie...",
        "Lerninhalt 2: Mathematische Grundlagen...",
        "Lerninhalt 3: Naturwissenschaftliche Experimente..."
    ]
    
    async with httpx.AsyncClient(base_url="http://localhost:8001") as client:
        tasks = [
            evaluate_content(client, content, ["overall_quality", "rechtliche_compliance"])
            for content in contents
        ]
        results = await asyncio.gather(*tasks)
    
    # Ergebnisse auswerten
    for i, result in enumerate(results):
        quality = result['results'][0]['value']
        compliance = result['results'][1]['value']
        print(f"Inhalt {i+1}: QualitÃ¤t {quality}/5.0, Compliance {'âœ“' if compliance else 'âœ—'}")

# AusfÃ¼hrung
asyncio.run(batch_evaluate())
```

### Beispiel 5: Error Handling

**Anwendungsfall:** Robuste Fehlerbehandlung

```python
import httpx
from typing import Dict, Any

def safe_evaluate(text: str, schemes: list) -> Dict[str, Any]:
    """Sichere Bewertung mit Fehlerbehandlung"""
    try:
        response = httpx.post(
            "http://localhost:8001/evaluate",
            json={
                "text": text,
                "schemes": schemes,
                "include_reasoning": true
            },
            timeout=30.0  # 30 Sekunden Timeout
        )
        response.raise_for_status()
        return {
            "success": True,
            "data": response.json()
        }
    
    except httpx.TimeoutException:
        return {
            "success": False,
            "error": "Timeout: Bewertung dauerte zu lange",
            "retry_recommended": True
        }
    
    except httpx.HTTPStatusError as e:
        return {
            "success": False,
            "error": f"HTTP {e.response.status_code}: {e.response.text}",
            "retry_recommended": e.response.status_code >= 500
        }
    
    except Exception as e:
        return {
            "success": False,
            "error": f"Unerwarteter Fehler: {str(e)}",
            "retry_recommended": False
        }

# Verwendung
result = safe_evaluate(
    "Beispieltext fÃ¼r Bewertung",
    ["neutralitaet_new", "sachrichtigkeit_new"]
)

if result["success"]:
    print("Bewertung erfolgreich:", result["data"])
else:
    print("Fehler:", result["error"])
    if result["retry_recommended"]:
        print("Wiederholung empfohlen")
```

## âš–ï¸ Deutsche RechtskonformitÃ¤t

### Abgedeckte Gesetze
- âœ… **Strafgesetzbuch (StGB)**: Volksverhetzung, Gewaltverherrlichung, Beleidigung
- âœ… **Jugendschutzgesetz (JuSchG)**: Altersgerechte Inhalte, Entwicklungsschutz
- âœ… **DSGVO**: Datenschutz, PersÃ¶nlichkeitsrechte
- âœ… **Kunsturhebergesetz (KUG)**: Bildrechte, Recht am eigenen Bild
- âœ… **NetzDG**: Strafbare Inhalte in sozialen Netzwerken
- âœ… **Digital Services Act (DSA)**: EU-Digitalrecht

### Automatische Risikobewertung
- ğŸ”´ **Critical**: Schwere Straftaten â†’ Sofortige Sperrung
- ğŸŸ  **High**: Erhebliche RechtsverstÃ¶ÃŸe â†’ Manuelle PrÃ¼fung
- ğŸŸ¡ **Medium**: Zivilrechtliche Folgen â†’ Ãœberarbeitung empfohlen
- ğŸŸ¢ **Low**: GeringfÃ¼gige VerstÃ¶ÃŸe â†’ Hinweis ausreichend

## ğŸ¯ Best Practices

### Schema-Auswahl fÃ¼r verschiedene AnwendungsfÃ¤lle

#### ğŸ“š **Bildungsinhalte (Empfohlen)**
```json
{"schemes": ["overall_quality", "rechtliche_compliance"]}
```

#### ğŸ‘¥ **User-Generated Content**
```json
{"schemes": ["jugendschutz_gate", "strafrecht_gate", "persoenlichkeitsrechte_gate"]}
```

#### ğŸ”¬ **Wissenschaftliche Texte**
```json
{"schemes": ["sachrichtigkeit_new", "neutralitaet_new"]}
```

#### âš¡ **Schnelle QualitÃ¤tsprÃ¼fung**
```json
{"schemes": ["neutralitaet_old", "sachrichtigkeit_old"], "include_reasoning": false}
```

### Performance & ZuverlÃ¤ssigkeit
- âœ… **Automatische Fehlerbehandlung** fÃ¼r ungÃ¼ltige Schema-IDs
- âœ… **Timeout-Protection** fÃ¼r KI-Bewertungen
- âœ… **Dependency-Validation** fÃ¼r derived Schemas
- âœ… **Rate Limiting** berÃ¼cksichtigen (OpenAI API)
- âœ… **Retry-Logic** fÃ¼r temporÃ¤re Fehler

## ğŸ”§ Entwicklung & Erweiterung

### API Status & Monitoring
```bash
# API Health Check
curl http://localhost:8001/health

# Alle verfÃ¼gbaren Schemas auflisten
curl http://localhost:8001/schemes

# Test-Bewertung durchfÃ¼hren
curl -X POST http://localhost:8001/evaluate \
  -H "Content-Type: application/json" \
  -d '{"text":"Testinhalt", "schemes":["neutralitaet_old"]}'
```

### Neues Schema erstellen
1. YAML-Datei in `schemes/` erstellen
2. Schema-Typ und Parameter definieren
3. Kriterien und Regeln spezifizieren
4. API neu starten fÃ¼r automatisches Laden

### Debugging & Logs
- âœ… **Structured Logging** mit Loguru
- âœ… **Request/Response Tracing**
- âœ… **Error Details** in API Responses
- âœ… **Schema Loading Status** beim Startup

## ğŸ“ˆ Produktionsstatus

### âœ… FunktionsfÃ¤hige Features
- ğŸŸ¢ **API Server**: LÃ¤uft stabil auf Port 8001
- ğŸŸ¢ **Alle Endpoints**: Health, Schemes, Evaluate funktionsfÃ¤hig
- ğŸŸ¢ **15 Bewertungsschemas**: VollstÃ¤ndig geladen und getestet
- ğŸŸ¢ **KI-Integration**: OpenAI GPT-4 Bewertungen
- ğŸŸ¢ **Swagger UI**: VollstÃ¤ndige interaktive Dokumentation
- ğŸŸ¢ **Error Handling**: Robuste Fehlerbehandlung
- ğŸŸ¢ **Schema Validation**: Pydantic-basierte Validierung

### ğŸ”„ Letzte Updates (2025-01-18)
- âœ… Fixed Swagger UI "Try it out" FunktionalitÃ¤t
- âœ… Erweiterte API-Dokumentation mit Beispielen
- âœ… Verbesserte Schema-Validierung fÃ¼r Binary Gates
- âœ… Dependency Injection KompatibilitÃ¤t

## ğŸ“ Lizenz & Rechtliches

Dieses System implementiert deutsche Rechtsstandards und ist fÃ¼r den Einsatz in Deutschland optimiert. Bei internationaler Nutzung sind lokale Gesetze zu beachten.

**âš ï¸ Haftungsausschluss**: Die automatische RechtsprÃ¼fung ersetzt keine juristische Beratung. Bei kritischen Inhalten sollte immer eine manuelle PrÃ¼fung erfolgen.

---

**ğŸš€ Ready for Production** | **ğŸ¤– LLM as Judge** | **ğŸ“š Full Documentation** | **ğŸ”§ Easy to Extend**
