# LLM Content Evaluator - KI-gest√ºtzte Inhaltsbewertung

üéØ **Produktive FastAPI-Anwendung** mit **LLM as Judge** Methodologie zur automatisierten Bewertung von Bildungsinhalten mit KI-gest√ºtzter Analyse, deutschen Rechtsstandards und p√§dagogischen Qualit√§tskriterien.

## üöÄ Features

- ‚úÖ **500+ Bewertungsindikatoren** in 70+ Teilschemas f√ºr umfassende Compliance-Pr√ºfung
- ‚úÖ **4 Master-Gates**: Strafrecht, Jugendschutz, Pers√∂nlichkeitsrechte, Datenschutz (kombinieren jeweils a/b Kataloge)
- ‚úÖ **4 Schema-Typen**: Ordinal, Checklist, Binary Gates, Derived (mit rekursiver Unterst√ºtzung)
- ‚úÖ **LLM as Judge Methodologie** mit OpenAI GPT-4 Integration
- ‚úÖ **Context-Awareness**: Unterscheidung zwischen UGC (content-only) und kommerziellen Plattformen (full compliance)
- ‚úÖ **Parallele Evaluierung**: Mehrere Schemas werden gleichzeitig verarbeitet (max. 20 parallele LLM-Calls, konfigurierbar)
- ‚úÖ **Request-Caching**: Wiederverwendung bereits berechneter Schemas ‚Äì spart LLM-Kosten und reduziert Latenz
- ‚úÖ **Singleton-Engine**: YAML-Schemas werden einmalig beim API-Start geladen
- ‚úÖ **Deutsche Rechtskonformit√§t**: StGB, DSGVO, JuSchG, JMStV, DSA, AVMD-RL, EU-KI-VO
- ‚úÖ **P√§dagogische Qualit√§t**: Didaktik, Neutralit√§t, Sachrichtigkeit, Aktualit√§t
- ‚úÖ **Modulare Qualit√§ts-Gates**: `neutrality_gate`, `factual_accuracy_gate`, `actuality_gate`, `media_appropriate_gate`, `linguistic_appropriateness_gate`, `didactics_gate`
- ‚úÖ **Jugendschutz**: 278 Indikatoren f√ºr Altersfreigaben (FSK 0/6/12/16/18 + AVS)
- ‚úÖ **RESTful API** mit vollst√§ndiger OpenAPI/Swagger Dokumentation
- ‚úÖ **Produktionsbereit** mit Error Handling und Validation
- ‚úÖ **Flexible Ausgabe**: Detaillierte Begr√ºndungen und Kriterien-Breakdown

## üìã √úbersicht aller Schemas

### Qualit√§tsbewertung (13 Schemas)

| Schema ID | Typ | Beschreibung | Skala | Kriterien |
|-----------|-----|--------------|-------|-----------|
| `sachrichtigkeit_new` | Checklist | Detaillierte Sachrichtigkeit | 10 Kriterien | Faktentreue, Quellenangaben, Wissenschaftlichkeit |
| `neutralitaet_new` | Checklist | Detaillierte Neutralit√§t | 10 Kriterien | Ausgewogenheit, Objektivit√§t, Meinungsvielfalt |
| `aktualitaet_new` | Checklist | Detaillierte Aktualit√§t | 10 Kriterien | Zeitgem√§√üheit, Relevanz, Updates |
| `didaktik_methodik_new` | Checklist | Detaillierte Didaktik | 10 Kriterien | Lernziele, Methoden, Verst√§ndlichkeit |
| `sprachliche_angemessenheit_new` | Checklist | Detaillierte Sprache | 10 Kriterien | Verst√§ndlichkeit, Stil, Zielgruppe, Grammatik |
| `medial_passend_new` | Checklist | Detaillierte Mediale Passung | 10 Kriterien | Technische Qualit√§t, Interaktivit√§t, Zug√§nglichkeit |
| `sachrichtigkeit_old` | Ordinal | Sachrichtigkeit (0-5) | 6 Stufen | Kompakte Bewertung der Faktentreue |
| `neutralitaet_old` | Ordinal | Neutralit√§t (0-5) | 6 Stufen | Kompakte Bewertung der Ausgewogenheit |
| `aktualitaet_old` | Ordinal | Aktualit√§t (0-5) | 6 Stufen | Kompakte Bewertung der Zeitgem√§√üheit |
| `sprachliche_angemessenheit_old` | Ordinal | Sprache (0-5) | 6 Stufen | Verst√§ndlichkeit, Stil, Zielgruppe |
| `didaktik_methodik_old` | Ordinal | Didaktik (0-5) | 6 Stufen | Kompakte p√§dagogische Bewertung |
| `medial_passend_old` | Ordinal | Mediale Passung (0-5) | 6 Stufen | Medieneignung, Darstellung |
| `overall_quality` | Derived | Gesamtqualit√§t | 0.0-5.0 | Gewichtete Kombination aller Dimensionen |

### Compliance & Rechtssicherheit - Master-Gates

Die API bietet **4 Master-Gates**, die jeweils die a/b Kataloge der Hauptrechtsbereiche kombinieren:

| Schema ID | Typ | Kombiniert | Output | Indikatoren | Beschreibung |
|-----------|-----|------------|--------|-------------|--------------|  
| `criminal_law_gate` | Master | 1A + 1B | 0-2 | 92 | **Strafrecht**: ILLEGAL (0) / KONTEXTABH√ÑNGIG (1) / LEGAL (2) |
| `protection_of_minors_gate` | Master | 2A + 2B | 0-18, 100 | 278 | **Jugendschutz**: FSK-Freigaben (0,6,12,16,18) + AVS (100) |
| `personal_law_gate` | Master | 3A + 3B | 0-3 | 88 | **Pers√∂nlichkeitsrechte**: KRITISCH (0) / STRUKTURELL (1) / CONTENT (2) / COMPLIANT (3) |
| `data_privacy_gate` | Master | 4A + 4B | 0-3 | 87 | **Datenschutz**: KRITISCH (0) / TRANSPARENZ (1) / DSGVO (2) / COMPLIANT (3) |

**Sub-Gates** (f√ºr granulare Pr√ºfungen):

| Schema ID | Typ | Beschreibung | Rechtsbasis | Indikatoren |
|-----------|-----|--------------|-------------|-------------|
| `criminal_law_1a_gate` | Binary | **Strafrecht 1A**: Per se illegal (Hard Illegal / AUA) | StGB, JMStV ¬ß4 | 49 |
| `criminal_law_1b_gate` | Binary | **Strafrecht 1B**: Kontextabh√§ngig strafbar | StGB, UrhG, BDSG | 43 |
| `protection_of_minors_2a_gate` | Binary | **Jugendschutz 2A**: Jugendgef√§hrdend (AVS-Pflicht) | JMStV ¬ß4 Abs.2 | 37 |
| `protection_of_minors_2b_gate` | Derived | **Jugendschutz 2B**: Entwicklungsbeeintr√§chtigend (FSK) | JMStV ¬ß5, JuSchG ¬ß14 | 241 |
| `personal_law_3a_gate` | Binary | **Pers√∂nlichkeitsrechte 3A**: Individuelle Verletzungen | GG, BGB, KUG, StGB | 44 |
| `personal_law_3b_gate` | Binary | **Pers√∂nlichkeitsrechte 3B**: Strukturelle Vorsorge | JuSchG ¬ß24a, DSA | 44 |
| `data_privacy_4a_gate` | Binary | **Datenschutz 4A**: Profiling & Einwilligung | DSGVO, TDDDG | 50 |
| `data_privacy_4b_gate` | Binary | **Datenschutz 4B**: Transparenz & KI-Kennzeichnung | MStV, DSA, EU-KI-VO | 37 |

**Hinweis**: Teilschemas (z.B. `*_part1`, `*_part2`) sind interne Bausteine und werden in der API-√úbersicht standardm√§√üig ausgeblendet (mit `?include_parts=true` sichtbar).

## üõ†Ô∏è Installation & Setup

### Voraussetzungen
- Python 3.8+
- OpenAI API Key (f√ºr KI-basierte Bewertung)
- FastAPI, Uvicorn, Pydantic (automatisch installiert)

### Schnellstart

```bash
# Repository klonen
git clone <repository-url>
cd api-scoring-quality/api-eval-25

# Umgebung einrichten
cp .env.example .env
# .env mit OpenAI API Key bearbeiten:
# OPENAI_API_KEY=your_api_key_here

# Dependencies installieren
pip install fastapi uvicorn openai pydantic loguru pyyaml

# Server starten
python main.py
```

üåê **Server l√§uft auf: http://localhost:8001**  
üìö **API Dokumentation: http://localhost:8001/docs**  
üîç **Alternative Docs: http://localhost:8001/redoc**

### üîÑ Startup Lifecycle

FastAPI initialisiert im `main.py` eine Singleton-Instanz der `EvaluationEngine` w√§hrend des Lifespan-Events:

```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    initialize_engine("schemes")  # l√§dt alle YAMLs einmalig
    yield
    shutdown_engine()
```

So werden die ~59 YAML-Dateien nur einmal beim Start geladen ‚Äì alle Endpoints greifen auf dieselbe Instanz zu.

### üìâ Logging & Monitoring

`loguru` unterscheidet nun zwischen:
- `INFO`: High-Level Ereignisse (Startup, Gesamtsumme Schemas)
- `DEBUG`: Detail-Informationen (Cache_hits, Rule-Auswertung, Dependency-Resultate)
- `ERROR`: Fehlgeschlagene Bewertungen

Setze `LOG_LEVEL=DEBUG` in der `.env`, um detaillierte Cache-Hits und Regelpr√ºfungen mitzuschreiben.

### ‚öôÔ∏è Umgebungsvariablen

Erstelle eine `.env` Datei im Projektverzeichnis:

```bash
# LLM Settings
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# Concurrency Control
MAX_CONCURRENT_LLM_CALLS=20

# APP Settings
LOG_LEVEL=INFO
SCHEMES_DIR=schemes

# API Configuration
API_HOST=0.0.0.0
API_PORT=8001
API_DEBUG=true

# Request Timeouts
HTTP_TIMEOUT_SECONDS=30
OPENAI_TIMEOUT_SECONDS=60
```

**Wichtige Variablen:**
- `MAX_CONCURRENT_LLM_CALLS`: Begrenzt parallele LLM-Aufrufe (Standard: 20)
  - Verhindert Rate Limits bei gro√üen Schemas (z.B. Gate 2B mit 50+ Teilschemas)
  - H√∂here Werte = schneller, aber mehr API-Last
  - Niedrigere Werte = langsamer, aber stabiler

## üîó API Endpoints

### üè• Health Check
```http
GET /health
```
**Status:** ‚úÖ Funktionsf√§hig  
**Zweck:** API-Status und geladene Schemas pr√ºfen

### üìã Schema-√úbersicht  
```http
GET /schemes?include_parts=false
```
**Status:** ‚úÖ Funktionsf√§hig  
**Zweck:** Alle verf√ºgbaren Bewertungsschemas auflisten (standardm√§√üig nur Master/Gate-Schemas)

**Query-Parameter:**
- `include_parts` (default: `false`): 
  - `false`: Nur Master-Gates und Sub-Gates (empfohlen f√ºr Endnutzer)
  - `true`: Alle Schemas inkl. interner Teilschemas (*_part1, *_part2, etc.)
- `context_type` (optional): Filtert serverseitig nach Scope ("content", "platform", "both") und spiegelt damit die Evaluationslogik.

### üéØ Text-Bewertung
```http
POST /evaluate
```
**Status:** ‚úÖ Funktionsf√§hig  
**Zweck:** KI-gest√ºtzte Bewertung von Bildungsinhalten

**Beispiel-Request:**
```json
{
    "text": "Die deutsche Wiedervereinigung war ein komplexer politischer Prozess...",
    "schemes": ["neutralitaet_new", "sachrichtigkeit_old", "rechtliche_compliance"],
    "include_reasoning": true
}
```

**Beispiel-Response:**
```json
{
    "results": [
        {
            "scheme_id": "neutralitaet_new",
            "value": 4.2,
            "label": "Weitgehend neutral",
            "confidence": 0.88,
            "reasoning": "Der Text stellt verschiedene Perspektiven ausgewogen dar...",
            "criteria": {
                "ausgewogenheit": {"value": 4, "reasoning": "Mehrere Standpunkte ber√ºcksichtigt"},
                "objektivitaet": {"value": 4, "reasoning": "Sachliche Darstellung ohne Wertungen"}
            }
        },
        {
            "scheme_id": "sachrichtigkeit_old",
            "value": 3,
            "label": "Inhaltlich √ºberwiegend korrekt"
        }
    ],
    "gates_passed": true,
    "overall_score": 3.6,
    "overall_label": "Gut",
    "metadata": {
        "processing_time_ms": 1250,
        "model_used": "gpt-4"
    }
}
```

## üéØ Context-Awareness (Content vs. Platform vs. Both)

Die API unterscheidet zwischen **reiner Inhaltsbewertung** (f√ºr UGC, Blogs) und **voller Platform-Compliance** (f√ºr kommerzielle Anbieter).

### Context-Typen

| Context | Scope-Filter | Beschreibung | Anwendungsfall |
|---------|--------------|--------------|----------------|
| `content` (Default) | Nur `content` + `both` | Bewertet nur den **Inhalt** selbst | UGC, Social Media, Blogs, News, YouTube-Videos |
| `platform` | Nur `platform` + `both` | Bewertet **Metadaten & technische Ma√ünahmen** | Streaming-Plattformen, App Stores, VOD-Dienste |
| `both` | Alle Scopes | **Volle Compliance-Pr√ºfung** (Inhalt + Plattform) | Audits, Rechtsberatung, kommerzielle Content-Pr√ºfung |

### Scope-Feld in YAML-Schemas

Jedes Gate-Rule hat ein `scope`-Feld, das die Anwendbarkeit definiert:

```yaml
gate_rules:
  - id: 2B-16-40
    description: "Realistische Gewalt mit Leidfolgen ohne Kontextualisierung"
    scope: content    # Wird bei context_type="content" gepr√ºft
    
  - id: 2B-16-08
    description: "Fehlende Alterskennzeichnung nach JuSchG"
    scope: platform   # Wird nur bei context_type="platform" gepr√ºft
    
  - id: 2B-16-39
    description: "Belastende Nachrichten ohne Einordnung"
    scope: both       # Wird immer gepr√ºft (content + platform)
```

**Scope-Werte:**
- `content`: Inhaltliche Eigenschaften (Gewalt, Sexualit√§t, Sprache, Themen)
- `platform`: Technische/organisatorische Ma√ünahmen (FSK-Label, Jugendschutzprogramme, Zeitsteuerung)
- `both`: Kombination (z.B. "Belastende Inhalte ohne Einordnung" = Inhalt + fehlender Warnhinweis)

### Beispiel: UGC-Bewertung (User-Generated Content)

```json
{
    "text": "brutale Kampfszene in einem Online Video",
    "schemes": ["protection_of_minors_gate"],
    "context_type": "content",
    "include_reasoning": true
}
```

**Gepr√ºft werden:**
- ‚úÖ Gewaltdarstellungen (`scope: content`)
- ‚úÖ Sexuelle Inhalte (`scope: content`)
- ‚úÖ Belastende Inhalte ohne Einordnung (`scope: both`)

**Ignoriert werden:**
- ‚ùå FSK-Kennzeichnung fehlt (`scope: platform`)
- ‚ùå Jugendschutzprogramm-Signalisierung (`scope: platform`)
- ‚ùå Zeitsteuerung 20:00-06:00 (`scope: platform`)

**Vorteil:** UGC-Inhalte werden nicht wegen fehlender technischer Ma√ünahmen abgelehnt!

### Beispiel: Kommerzielle Plattform (Netflix, Amazon Prime)

```json
{
    "text": "Film mit FSK 16 Label, aber keine Zeitsteuerung implementiert",
    "schemes": ["protection_of_minors_gate"],
    "context_type": "platform",
    "include_reasoning": true
}
```

**Gepr√ºft werden:**
- ‚úÖ FSK-Kennzeichnung vorhanden? (`scope: platform`)
- ‚úÖ Jugendschutzprogramm-Signalisierung? (`scope: platform`)
- ‚úÖ Zeitsteuerung 22:00-06:00 f√ºr FSK 16? (`scope: platform`)
- ‚úÖ Belastende Inhalte ohne Einordnung (`scope: both`)

**Ignoriert werden:**
- ‚ùå Inhaltliche Gewaltbewertung (`scope: content`) - wird als durch FSK-Label abgedeckt betrachtet

### Beispiel: Vollst√§ndiger Audit (Beides)

```json
{
    "text": "...",
    "schemes": ["criminal_law_gate", "protection_of_minors_gate", "data_privacy_gate"],
    "context_type": "both",
    "include_reasoning": true
}
```

**Gepr√ºft werden:** Alle Rules unabh√§ngig vom Scope

### Automatische Keyword-Erkennung

Das System klassifiziert Rules automatisch anhand von Keywords in der Beschreibung:

**Content-Rules** (Inhaltliche Eigenschaften):
- Gewalt, Darstellung, Thematisierung, Bedrohung, Sexualit√§t
- Brutal, explizit, zeigt, enth√§lt, verherrlicht
- Diskriminierung, Hassrede, Beleidigung

**Platform-Rules** (Technische Ma√ünahmen):
- Fehlende Kennzeichnung, Keine Altersfreigabe, Unzureichende Ma√ünahmen
- Zeitsteuerung, Jugendschutzprogramm, FSK-Label, PIN-Schutz
- Meldesystem, Elternkontrollen, Voreinstellungen

**Both-Rules** (Kombination):
- "ohne Einordnung", "ohne Warnhinweis", "ohne Kontextualisierung"
- Inhaltsproblem + fehlende Plattform-Ma√ünahme

### Best Practice: Context-Typ W√§hlen

| Anwendungsfall | Empfohlener Context | Begr√ºndung |
|----------------|---------------------|------------|
| **Social Media Post** | `content` | Nur Inhalt relevant, keine Plattform-Verantwortung des Posters |
| **YouTube Video (Creator)** | `content` | Creator verantwortlich f√ºr Inhalt, nicht f√ºr Plattform-Features |
| **Streaming-Dienst (Betreiber)** | `platform` | Pr√ºfung der technischen Jugendschutzma√ünahmen |
| **App Store (Review)** | `platform` | Pr√ºfung der Metadaten und Kennzeichnungen |
| **Rechtsberatung/Audit** | `both` | Vollst√§ndige Compliance-Pr√ºfung |
| **Content-Moderation** | `content` | Schnelle Inhaltspr√ºfung ohne Plattform-Overhead |

## üìñ YAML Schema-Parameter - Detaillierte Anleitung

### Grundstruktur aller Schemas

Jedes YAML-Schema folgt einer einheitlichen Grundstruktur:

```yaml
# Eindeutige Identifikation
id: schema_identifier
name: "Benutzerfreundlicher Anzeigename"
description: "Detaillierte Beschreibung des Bewertungszwecks"
dimension: dimension_name  # Technischer Dimensionsname
type: ordinal|checklist|binary_gate|derived
version: "1.0"

# Ausgabeformat definieren
output_range:
  min: 0      # Minimaler Wert
  max: 5      # Maximaler Wert  
  type: int   # int, float oder boolean
  values: [0, 1, 2, 3, 4, 5]  # Optional: Erlaubte Werte
```

**Pflichtfelder:**
- `id`: Eindeutige Schema-ID (keine Leerzeichen, Kleinbuchstaben)
- `name`: Anzeigename f√ºr Benutzeroberfl√§che
- `type`: Schema-Typ bestimmt Bewertungslogik
- `output_range`: Definiert m√∂gliche Ausgabewerte

### Schema-Typen im Detail

#### 1. Ordinal Schema - Anker-basierte Bewertung (0-5 Skala)

Ordinal-Schemas verwenden vordefinierte Anker f√ºr konsistente Bewertungen:

```yaml
id: neutralitaet_old
name: "Neutralit√§t (Ordinal)"
description: "Bewertung der politischen und weltanschaulichen Neutralit√§t"
dimension: neutrality
type: ordinal
version: "1.0"

output_range:
  min: 0
  max: 5
  type: int

# Bewertungsstrategie
strategy: first_match  # oder best_fit

# Anker in absteigender Reihenfolge (5 ‚Üí 0)
anchors:
  - value: 5
    label: "Vollst√§ndig neutral"
    criteria: |
      - Alle Standpunkte werden fair dargestellt
      - Keine erkennbare politische Tendenz
      - Ausgewogene Quellenauswahl
      - Objektive Sprache durchgehend
      
  - value: 4
    label: "Weitgehend neutral"
    criteria: |
      - √úberwiegend ausgewogene Darstellung
      - Minimale Tendenz erkennbar
      - Verschiedene Perspektiven ber√ºcksichtigt
      
  - value: 3
    label: "Teilweise neutral"
    criteria: |
      - Grunds√§tzlich um Neutralit√§t bem√ºht
      - Deutliche Tendenz in eine Richtung
      - Nicht alle Standpunkte gleichwertig dargestellt
      
  - value: 2
    label: "Wenig neutral"
    criteria: |
      - Starke Tendenz erkennbar
      - Einseitige Quellenauswahl
      - Gegenpositionen nur oberfl√§chlich behandelt
      
  - value: 1
    label: "Einseitig"
    criteria: |
      - Deutlich parteiische Darstellung
      - Wichtige Gegenpositionen fehlen
      - Wertende Sprache dominiert
      
  - value: 0
    label: "Stark einseitig"
    criteria: |
      - Propagandistische Darstellung
      - Keine Ber√ºcksichtigung anderer Standpunkte
      - Manipulative oder hetzerische Sprache

# Fallback bei unklaren F√§llen
default:
  value: 0
  label: "Unbewertet"
  reasoning: "Keine ausreichenden Informationen f√ºr Bewertung"
  confidence: 0.0

# Zus√§tzliche Metadaten
labels:
  "5": "Exzellent neutral"
  "4": "Gut neutral"
  "3": "Akzeptabel"
  "2": "Verbesserungsbed√ºrftig"
  "1": "Problematisch"
  "0": "Inakzeptabel"
```

**Strategien:**
- `first_match`: Erste passende Bewertung wird verwendet
- `best_fit`: Beste √úbereinstimmung wird gesucht

**Vollst√§ndiges Beispiel:** `neutralitaet_old.yaml`

#### 2. Checklist Schema - Kriterien-basierte Bewertung

Checklist-Schemas bewerten anhand gewichteter Einzelkriterien mit **kompakter Strukturbeschreibung**:

```yaml
id: sachrichtigkeit_new
name: "Sachrichtigkeit (Detailliert)"
description: "Umfassende Bewertung der faktischen Korrektheit"
dimension: factuality
type: checklist_additive
version: "1.0"

output_range:
  min: 0.0
  max: 5.0
  type: float

# Einzelkriterien mit strukturierten Werten (NEUE KOMPAKTE STRUKTUR)
items:
  - id: faktentreue
    prompt: "Sind alle Fakten und Aussagen korrekt und verifizierbar?"
    weight: 2.5
    values:
      1: {score: 0.25, description: "Viele falsche oder ungepr√ºfte Aussagen"}
      2: {score: 0.5, description: "Einige faktische Fehler oder Ungenauigkeiten"}
      3: {score: 0.75, description: "√úberwiegend korrekte Fakten, wenige Fehler"}
      4: {score: 1.0, description: "Alle Fakten korrekt und gut verifizierbar"}
      na: null
      
  - id: quellenangaben
    prompt: "Sind alle Behauptungen mit seri√∂sen Quellen belegt?"
    weight: 2.0
    values:
      1: {score: 0.25, description: "Keine oder unzuverl√§ssige Quellenangaben"}
      2: {score: 0.5, description: "Wenige oder teilweise fragw√ºrdige Quellen"}
      3: {score: 0.75, description: "Gute Quellenangaben, meist seri√∂s"}
      4: {score: 1.0, description: "Vollst√§ndige, seri√∂se und aktuelle Quellenangaben"}
      na: null

# Aggregation mit gewichtetem Mittelwert
aggregator:
  strategy: weighted_mean
  params:
    missing: ignore
    scale_factor: 5.0  # Skaliert von 0-1 auf 0-5

# Labels f√ºr Ausgabe
labels:
  "0.0": "Unzureichend"
  "1.0": "Mangelhaft"
  "2.0": "Ausreichend"
  "3.0": "Befriedigend"
  "4.0": "Gut"
  "5.0": "Sehr gut"
```

**Neue Kompakte Struktur:**
- **Strukturierte Werte:** `{score: 0.25, description: "..."}` statt einfacher Kommentare
- **Bessere LLM-Prompts:** Beschreibungen werden direkt in Bewertungsprompts eingebunden
- **Einheitliche Skalierung:** Alle Kriterien verwenden 1-4 Level mit 0.25-1.0 Scores

**Vollst√§ndiges Beispiel:** `sachrichtigkeit_new.yaml`, `neutralitaet_new.yaml`, `sprachliche_angemessenheit_new.yaml`, `medial_passend_new.yaml`

#### 3. Binary Gate - Pass/Fail Bewertung

Binary Gates sind K.O.-Kriterien f√ºr Compliance-Pr√ºfungen:

```yaml
id: strafrecht_gate
name: "Strafrechtliche Unbedenklichkeit"
description: "Pr√ºfung auf Verst√∂√üe gegen deutsches Strafrecht"
dimension: legal_compliance
type: binary_gate
version: "1.0"

output_range:
  values: [true, false]
  type: boolean

# Pr√ºfkriterien (wird in criteria-Feld dokumentiert)
criteria: |
  Automatische Pr√ºfung auf strafrechtlich relevante Inhalte:
  - Volksverhetzung (¬ß 130 StGB)
  - Gewaltverherrlichung (¬ß 131 StGB)
  - Beleidigung und Verleumdung (¬ß 185-187 StGB)
  - Bedrohung (¬ß 241 StGB)
  - Verfassungswidrige Symbole (¬ß 86a StGB)

# Gate-Regeln (Reihenfolge wichtig!)
gate_rules:
  - condition: "volksverhetzung"
    action: reject
    reason: "Inhalt enth√§lt volksverhetzende √Ñu√üerungen (¬ß 130 StGB)"
    severity: critical
    legal_reference: "¬ß 130 StGB"
    confidence: 0.9
    
  - condition: "gewaltverherrlichung"
    action: reject
    reason: "Inhalt verherrlicht Gewalt (¬ß 131 StGB)"
    severity: critical
    legal_reference: "¬ß 131 StGB"
    confidence: 0.85
    
  - condition: "beleidigung"
    action: reject
    reason: "Inhalt enth√§lt Beleidigungen (¬ß 185-187 StGB)"
    severity: medium
    legal_reference: "¬ß 185-187 StGB"
    confidence: 0.7
    
  - condition: "bedrohung"
    action: reject
    reason: "Inhalt enth√§lt Bedrohungen (¬ß 241 StGB)"
    severity: high
    legal_reference: "¬ß 241 StGB"
    confidence: 0.8

# Standard-Aktion wenn keine Regel greift
default_action: pass

# Automatische Keyword-Erkennung
detection_patterns:
  volksverhetzung:
    - "holocaustleugnung"
    - "rassenhass"
    - "judenhass"
    - "ausl√§nder raus"
    - "vernichtung"
    
  gewaltverherrlichung:
    - "folter verherrlichen"
    - "gewalt glorifizieren"
    - "hinrichtung feiern"
    - "sadismus"
    
  beleidigung:
    - "idiot"
    - "schwachkopf"
    - "versager"
    # (Kontext-abh√§ngig)
    
  bedrohung:
    - "ich bringe dich um"
    - "du bist tot"
    - "warte nur ab"

# Severity-Level Definitionen
severity_levels:
  critical: "Schwere Straftaten mit Gef√§ngnisstrafe"
  high: "Straftaten mit erheblicher gesellschaftlicher Relevanz"
  medium: "Rechtsverst√∂√üe mit zivilrechtlichen Konsequenzen"
  low: "Geringf√ºgige Rechtsverst√∂√üe"

# Compliance-Referenzen
compliance_references:
  - "Strafgesetzbuch (StGB)"
  - "Netzwerkdurchsetzungsgesetz (NetzDG)"
  - "Digital Services Act (DSA)"
```

**Gate-Logik:**
1. Regeln werden in Reihenfolge gepr√ºft
2. Erste zutreffende Regel bestimmt Ergebnis
3. Bei keiner Regel: `default_action`

**Severity-Levels:**
- `critical`: Sofortige Sperrung erforderlich
- `high`: Manuelle Pr√ºfung erforderlich
- `medium`: Warnung an Nutzer
- `low`: Hinweis ausreichend

**Vollst√§ndiges Beispiel:** `strafrecht_gate.yaml`

#### 4. Derived Schema - Kombination anderer Schemas

Derived Schemas kombinieren Ergebnisse anderer Schemas:

```yaml
id: overall_quality
name: "Gesamtqualit√§t"
description: "Gewichtete Kombination aller Qualit√§tsdimensionen"
dimension: overall_quality
type: derived
version: "2.0"

output_range:
  min: 0.0
  max: 5.0
  type: float

# Abh√§ngigkeiten (m√ºssen vorher ausgewertet werden)
dependencies:
  - neutralitaet_old
  - aktualitaet_old
  - sachrichtigkeit_old
  - sprachliche_angemessenheit_old
  - didaktik_methodik_old
  - medial_passend_old

# Kombinationsregeln
rules:
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 0
      - dimension: factuality
        operator: ">="
        value: 0
    value: "weighted_average"
    label: "Gewichtete Gesamtbewertung"
    reasoning: "Berechnung basierend auf gewichteten Einzeldimensionen"
    confidence: 0.9
    
    # Gewichtung der Dimensionen
    weights:
      neutrality: 2.0              # Neutralit√§t (wichtig)
      timeliness: 1.5              # Aktualit√§t
      factuality: 2.5              # Sachrichtigkeit (sehr wichtig)
      language_appropriateness: 1.5 # Sprachliche Angemessenheit
      pedagogy: 2.0                # Didaktik/Methodik (wichtig)
      media_appropriateness: 1.0    # Mediale Passung
      
  # Spezialregel f√ºr niedrige Sachrichtigkeit
  - conditions:
      - dimension: factuality
        operator: "<"
        value: 2.0
    value: 1.0
    label: "Unzureichende Sachrichtigkeit"
    reasoning: "Niedrige Sachrichtigkeit f√ºhrt zu schlechter Gesamtbewertung"
    confidence: 0.95

# Fallback
default:
  value: 0.0
  label: "Unbewertet"
  reasoning: "Keine ausreichenden Daten f√ºr Gesamtbewertung"
  confidence: 0.0

# Ausgabe-Labels
labels:
  "4.5-5.0": "Exzellente Qualit√§t"
  "3.5-4.4": "Gute Qualit√§t"
  "2.5-3.4": "Akzeptable Qualit√§t"
  "1.5-2.4": "Verbesserungsbed√ºrftig"
  "0.0-1.4": "Unzureichende Qualit√§t"

# Mathematische Operationen
calculation_method: weighted_average
normalization: true
```

**Kombinationslogik:**
- `weighted_average`: Gewichteter Durchschnitt (f√ºr Gesamtqualit√§t)
- `sum`: Einfache Summe aller Werte (f√ºr Split-Schemas)
- `min`: Minimum aller Werte
- `max`: Maximum aller Werte
- `and_gate`: Alle m√ºssen TRUE sein
- `or_gate`: Mindestens einer TRUE

**Operatoren f√ºr Bedingungen:**
- `==`: Gleich
- `!=`: Ungleich
- `>`: Gr√∂√üer
- `>=`: Gr√∂√üer oder gleich
- `<`: Kleiner
- `<=`: Kleiner oder gleich
- `in`: Wert in Liste
- `not_in`: Wert nicht in Liste

**Performance-Optimierung:**
- Dependencies werden **parallel ausgef√ºhrt** (asyncio.gather) f√ºr maximale Geschwindigkeit
- Mehrere Schemas im selben Request werden ebenfalls parallel evaluiert
- Binary Gates: **LLM-Aufrufe laufen parallel**, aber logische Auswertung ist sequenziell (Early Exit bei Fehlschlag im Top-Level)

**Ausgabestruktur f√ºr Derived Schemas:**

Derived Schemas geben sowohl die Einzelergebnisse der Dependencies als auch das kombinierte Gesamtergebnis zur√ºck:

```json
{
  "scheme_id": "overall_quality",
  "dimension": "overall_quality",
  "value": 3.85,
  "label": "Gute Qualit√§t",
  "reasoning": "Gewichteter Durchschnitt: 3.85/5.0\n\nEinzelbewertungen:\n- neutrality: 4.0 √ó 2.0\n- factuality: 4.5 √ó 2.5\n...",
  "confidence": 0.9,
  "scale_info": {
    "type": "derived",
    "method": "weighted_average",
    "dependencies": 6,
    "weights": {"neutrality": 2.0, "factuality": 2.5}
  },
  "criteria": {
    "neutralitaet_old": {
      "dimension": "neutrality",
      "value": 4.0,
      "label": "Weitgehend neutral",
      "weight": 2.0,
      "confidence": 0.88,
      "reasoning": "Der Text stellt verschiedene Perspektiven ausgewogen dar...",
      "scale_info": {
        "type": "ordinal_rubric",
        "range": {"min": 0, "max": 5},
        "anchors": 6
      },
      "criteria": null
    },
    "sachrichtigkeit_new": {
      "dimension": "factuality", 
      "value": 4.5,
      "label": "Hohe Sachrichtigkeit",
      "weight": 2.5,
      "confidence": 0.8,
      "reasoning": "Fakten sind korrekt und gut belegt...",
      "scale_info": {
        "type": "checklist_additive",
        "raw_range": "0.0-1.0",
        "normalized_range": "0.0-5.0"
      },
      "criteria": {
        "fakten_belegt": {
          "name": "Faktische Belege",
          "response": "4",
          "normalized_score": 4.0,
          "weight": 1.0,
          "reasoning": "Alle wichtigen Aussagen sind belegt"
        },
        "quellenangaben": {
          "name": "Quellenangaben",
          "response": "4",
          "normalized_score": 4.0,
          "weight": 1.0,
          "reasoning": "Quellen sind korrekt angegeben"
        }
      }
    }
  }
}
```

**Vollst√§ndige Transparenz:** Jedes Dependency-Schema enth√§lt:
- `value`, `label`: Bewertungsergebnis
- `confidence`: Konfidenzwert der Bewertung
- `reasoning`: Vollst√§ndige Begr√ºndung (nicht verk√ºrzt)
- `scale_info`: Metadaten zum verwendeten Schema-Typ
- `criteria`: Verschachtelte Sub-Kriterien (bei Checklists)

**Vollst√§ndiges Beispiel:** `overall_quality.yaml`, `rechtliche_compliance.yaml`

### Erweiterte YAML-Features

#### Conditional Logic (Bedingte Logik)

```yaml
rules:
  # Mehrere Bedingungen (UND-verkn√ºpft)
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 3
      - dimension: factuality
        operator: ">="
        value: 4
    value: 4.5
    label: "Hohe Qualit√§t"
    
  # ODER-Verkn√ºpfung mit condition_logic
  - condition_logic: "OR"
    conditions:
      - dimension: neutrality
        operator: "=="
        value: 5
      - dimension: factuality
        operator: "=="
        value: 5
    value: 4.0
    label: "Exzellenz in einer Dimension"
```

#### Gate Logic f√ºr Binary Schemas

```yaml
# UND-Verkn√ºpfung (alle Gates m√ºssen TRUE sein)
gate_logic: "AND"

# ODER-Verkn√ºpfung (mindestens ein Gate TRUE)
gate_logic: "OR"

# Beispiel: Rechtliche Unbedenklichkeit
dependencies:
  - content_gate
  - jugendschutz_gate
  - strafrecht_gate
  - persoenlichkeitsrechte_gate

rules:
  - conditions:
      - dimension: content_safety
        operator: "=="
        value: true
      - dimension: youth_protection
        operator: "=="
        value: true
      - dimension: legal_compliance
        operator: "=="
        value: true
      - dimension: personality_rights
        operator: "=="
        value: true
    value: true
    label: "Rechtlich unbedenklich"
```

#### Regeln f√ºr Derived Schema-Verkn√ºpfungen

**Grundprinzipien:**

1. **Dependencies m√ºssen existieren**: Alle Schemas in `dependencies` m√ºssen als YAML-Dateien vorhanden sein
2. **Keine Zirkelbez√ºge**: Schema A darf nicht direkt oder indirekt auf sich selbst verweisen
3. **Dimension-Matching**: Die `dimension` in Bedingungen muss mit der `dimension` der Dependency-Schemas √ºbereinstimmen
4. **Richtige Datentypen**: Werte in Bedingungen m√ºssen zum `output_range.type` der Dependency passen

**Verkn√ºpfungsarten:**

```yaml
# 1. Gewichteter Durchschnitt (f√ºr Qualit√§tsmetriken)
rules:
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 0
    value: "weighted_average"
    weights:
      neutrality: 2.0
      factuality: 2.5
      pedagogy: 2.0
      # Summe der Gewichte muss nicht 1.0 sein
      # Wird automatisch normalisiert

# 2. UND-Verkn√ºpfung (f√ºr Compliance)
rules:
  - conditions:
      - dimension: youth_protection_legal
        operator: "=="
        value: 1
      - dimension: legal_compliance
        operator: "=="
        value: 1
    value: 1
    label: "COMPLIANT"

# 3. ODER-Verkn√ºpfung (mindestens eine Bedingung)
rules:
  - conditions:
      - dimension: neutrality
        operator: ">="
        value: 4
    value: 4.0
    label: "Exzellent in Neutralit√§t"
  - conditions:
      - dimension: factuality
        operator: ">="
        value: 4
    value: 4.0
    label: "Exzellent in Sachrichtigkeit"

# 4. Hierarchische Regeln (erste passende Regel gewinnt)
rules:
  # Spezialfall: Niedrige Sachrichtigkeit ‚Üí Schlechte Bewertung
  - conditions:
      - dimension: factuality
        operator: "<"
        value: 2.0
    value: 1.0
    label: "Unzureichend"
  # Normalfall: Gewichteter Durchschnitt
  - conditions:
      - dimension: factuality
        operator: ">="
        value: 2.0
    value: "weighted_average"
    label: "Berechnet"

# 5. Summen-Aggregation (f√ºr Split-Schemas)
# Ideal f√ºr gro√üe Schemas (z.B. 50 Items) in Teilschemas (z.B. 5√ó10)
id: sachrichtigkeit_gesamt
dependencies:
  - sachrichtigkeit_teil1  # Items 1-10
  - sachrichtigkeit_teil2  # Items 11-20
  - sachrichtigkeit_teil3  # Items 21-30
  - sachrichtigkeit_teil4  # Items 31-40
  - sachrichtigkeit_teil5  # Items 41-50

rules:
  - conditions:
      - dimension: factuality_part1
        operator: ">="
        value: 0
    value: "sum"
    label: "Gesamtbewertung"
    reasoning: "Summe aller Teilbewertungen"

# Beispiel: 5 Teilschemas √† 10 Punkte = max. 50 Punkte gesamt
output_range:
  min: 0.0
  max: 50.0
  type: float
```

**Split-Schema-Pattern f√ºr gro√üe Bewertungen:**

Gro√üe Schemas (>30 Items) k√∂nnen in kleinere Teilschemas aufgeteilt werden f√ºr:

1. **Performance-Optimierung**: Teilschemas werden parallel evaluiert
2. **Token-Limits**: Umgehung von LLM-Context-Limits
3. **Modularit√§t**: Einfachere Wartung und Updates einzelner Teile
4. **Caching**: Teilschemas k√∂nnen separat gecacht werden

**Beispiel-Struktur:**
```
sachrichtigkeit_teil1.yaml (Items 1-10)   ‚Üí Score 0-10
sachrichtigkeit_teil2.yaml (Items 11-20)  ‚Üí Score 0-10
sachrichtigkeit_teil3.yaml (Items 21-30)  ‚Üí Score 0-10
sachrichtigkeit_teil4.yaml (Items 31-40)  ‚Üí Score 0-10
sachrichtigkeit_teil5.yaml (Items 41-50)  ‚Üí Score 0-10
    ‚Üì
sachrichtigkeit_gesamt.yaml (Derived)     ‚Üí Score 0-50 (Summe)
```

**Vorteile:**
- ‚úÖ **5√ó schneller** durch Parallelisierung (5 Schemas gleichzeitig)
- ‚úÖ Jedes Teilschema bleibt unter Token-Limits
- ‚úÖ Fehler in einem Teil beeintr√§chtigen andere nicht
- ‚úÖ Einzelne Teile k√∂nnen aktualisiert werden ohne Gesamtschema zu √§ndern

**Best Practices:**

- ‚úÖ **Aussagekr√§ftige Labels**: Labels sollten den Zustand klar beschreiben
- ‚úÖ **Fallback definieren**: Immer ein `default` f√ºr unerwartete F√§lle
- ‚úÖ **Confidence-Werte**: H√∂here confidence bei strengeren Bedingungen
- ‚úÖ **Dokumentation**: `reasoning` sollte die Logik erkl√§ren
- ‚úÖ **Split-Schemas**: Bei >30 Items in Teilschemas aufteilen
- ‚ö†Ô∏è **Reihenfolge**: Spezifische Regeln vor allgemeinen Regeln
- ‚ö†Ô∏è **Gewichte sinnvoll**: Wichtigere Dimensionen st√§rker gewichten

**H√§ufige Fehler vermeiden:**

```yaml
# ‚ùå FALSCH: Zirkelbezug
# overall_quality.yaml:
dependencies:
  - neutralitaet_old
  - overall_quality  # Fehler: Selbstreferenz!

# ‚ùå FALSCH: Falsche Dimension
dependencies:
  - neutralitaet_old  # dimension: neutrality
rules:
  - conditions:
      - dimension: neutralitaet  # Fehler: Muss "neutrality" sein!
        operator: ">="
        value: 3

# ‚ùå FALSCH: Typ-Mismatch
dependencies:
  - jugendschutz_gate  # output_range.type: int (0 oder 1)
rules:
  - conditions:
      - dimension: youth_protection_legal
        operator: ">="
        value: 0.5  # Fehler: Muss integer sein!

# ‚úÖ RICHTIG: Korrekte Verkn√ºpfung
dependencies:
  - jugendschutz_gate  # dimension: youth_protection_legal
rules:
  - conditions:
      - dimension: youth_protection_legal
        operator: "=="
        value: 1  # Korrekt: Integer-Wert
```

#### Metadata und Dokumentation

```yaml
# Zus√§tzliche Metadaten
metadata:
  author: "Qualit√§tsteam"
  created: "2025-01-17"
  last_modified: "2025-01-17"
  review_cycle: "quarterly"
  
# Dokumentation f√ºr Entwickler
documentation:
  purpose: "Bewertung der Neutralit√§t in Bildungsinhalten"
  methodology: "Anker-basierte Bewertung mit KI-Unterst√ºtzung"
  validation: "Getestet mit 100+ Beispieltexten"
  
# Konfiguration f√ºr KI-Bewertung
ai_config:
  model: "gpt-4"
  temperature: 0.1
  max_tokens: 500
  prompt_template: "Bewerte die Neutralit√§t des folgenden Textes..."
```

### Validierung und Testing

#### Schema-Validierung

```bash
# YAML-Syntax pr√ºfen
python -c "import yaml; yaml.safe_load(open('schemes/schema.yaml'))"

# Schema-Struktur validieren
python -m core.evaluation --validate-schema schemes/schema.yaml

# Alle Schemas validieren
python -m core.evaluation --validate-all
```

#### Test-Cases definieren

```yaml
# Optional: Test-Cases im Schema
test_cases:
  - input: "Neutral formulierter Text √ºber Politik..."
    expected_value: 4
    expected_label: "Weitgehend neutral"
    
  - input: "Stark einseitiger Text..."
    expected_value: 1
    expected_label: "Einseitig"
```

### Best Practices f√ºr YAML-Schemas

#### 1. Naming Conventions
```yaml
# Schema-IDs: lowercase, underscore
id: sachrichtigkeit_new

# Dimensionen: englisch, lowercase
dimension: factuality

# Kriterien-IDs: deutsch, underscore
criteria:
  - id: faktentreue
  - id: quellenangaben
```

#### 2. Gewichtung
```yaml
# Wichtigste Kriterien: 2.0-2.5
# Normale Kriterien: 1.0-1.5
# Erg√§nzende Kriterien: 0.5-1.0
weights:
  factuality: 2.5      # Sehr wichtig
  neutrality: 2.0      # Wichtig
  timeliness: 1.5      # Normal
  media_fit: 1.0       # Erg√§nzend
```

#### 3. Confidence-Werte
```yaml
# Hohe Sicherheit: 0.9-1.0
# Mittlere Sicherheit: 0.7-0.8
# Niedrige Sicherheit: 0.5-0.6
confidence: 0.9
```

#### 4. Dokumentation
```yaml
# Immer aussagekr√§ftige Beschreibungen
description: "Bewertung der faktischen Korrektheit und Quellenqualit√§t"

# Konkrete Beispiele f√ºr Kriterien
examples:
  - "Zahlen sind durch seri√∂se Quellen belegt"
  - "Historische Fakten sind korrekt dargestellt"
```

## üîÑ Derived Schemas - Kombinationslogik & Rekursion

### Rekursive Evaluation (Master-Gates)

Die API unterst√ºtzt **mehrstufige Derived-Schemas** f√ºr komplexe Evaluierungen:

```yaml
# Ebene 3: Master-Gate (kombiniert Sub-Gates)
id: criminal_law_gate
dependencies:
  - criminal_law_1a_gate  # Ebene 2: Sub-Gate
  - criminal_law_1b_gate  # Ebene 2: Sub-Gate

# Ebene 2: Sub-Gate (kombiniert Parts)
id: criminal_law_1a_gate
dependencies:
  - criminal_law_1a_part1  # Ebene 1: Part-Schema
  - criminal_law_1a_part2
  - criminal_law_1a_part3
  # ... bis part10

# Ebene 1: Part-Schema (eigentliche LLM-Evaluation)
id: criminal_law_1a_part1
type: binary_gate
gate_rules: [...]  # Tats√§chliche Pr√ºfkriterien
```

**Hierarchie:**
```
Master-Gate (Ebene 3)
  ‚Üì [parallel]
Sub-Gates (Ebene 2)
  ‚Üì [parallel]
Part-Schemas (Ebene 1)
  ‚Üì [parallel]
LLM-Calls
```

**Vorteile der Rekursion:**
- ‚úÖ **Performance**: Alle Dependencies werden parallel evaluiert
- ‚úÖ **Modularit√§t**: √Ñnderungen auf einer Ebene beeinflussen h√∂here Ebenen nicht
- ‚úÖ **Transparenz**: Vollst√§ndige Kriterien-Hierarchie in der Response
- ‚úÖ **Flexibilit√§t**: Master-Gates k√∂nnen granular (Sub-Gates) oder vollst√§ndig (Master-Gate) abgefragt werden

**Beispiel-Aufruf:**

```json
// Master-Gate (empfohlen f√ºr Endnutzer)
{"schemes": ["criminal_law_gate"]}  
// ‚Üí Evaluiert automatisch 1A + 1B ‚Üí jeweils 10+8 Parts ‚Üí 200+ Indikatoren

// Sub-Gate (f√ºr granulare Pr√ºfung)
{"schemes": ["criminal_law_1a_gate"]}  
// ‚Üí Nur Hard Illegal (1A) ‚Üí 10 Parts ‚Üí 49 Indikatoren

// Part-Schema (f√ºr Entwickler/Debugging)
{"schemes": ["criminal_law_1a_part1"]}  
// ‚Üí Nur Verfassungsfeindliche Symbole ‚Üí 5 Indikatoren
```

**Response-Struktur** (verschachtelt):

```json
{
  "scheme_id": "criminal_law_gate",
  "value": 2,  // LEGAL
  "criteria": {
    "criminal_law_1a_gate": {
      "value": 1,  // PASS
      "criteria": {
        "criminal_law_1a_part1": {
          "value": 1,  // PASS
          "criteria": {
            "aspekt_1": {"passed": true, "rule_id": "1A-01"},
            "aspekt_2": {"passed": true, "rule_id": "1A-02"}
          }
        }
      }
    },
    "criminal_law_1b_gate": {"value": 1}
  }
}
```

**Best Practice:**
- **Endnutzer**: Immer Master-Gates verwenden (`*_gate` ohne Zahl)
- **Entwickler**: Sub-Gates f√ºr spezifische Tests
- **Debugging**: Part-Schemas nur bei Fehlersuche

### UND-Verkn√ºpfung (AND Logic)
```yaml
gate_logic: "AND"
```
Alle Bedingungen m√ºssen erf√ºllt sein.

**Beispiel:** `rechtliche_unbedenklichkeit_derived.yaml`
- Alle 4 Gates m√ºssen `true` sein
- Ein `false` f√ºhrt zur Gesamtablehnung

### ODER-Verkn√ºpfung (OR Logic)
```yaml
gate_logic: "OR"
```
Mindestens eine Bedingung muss erf√ºllt sein.

### Gewichtete Kombination
```yaml
rules:
  - conditions: [...]
    value: "weighted_average"
    weights:
      neutrality: 2.0
      factuality: 2.5
      timeliness: 1.5
```

## üß™ Live-Tests & Swagger UI

**Interaktive API-Tests:** http://localhost:8001/docs

- ‚úÖ **"Try it out" Funktionalit√§t** f√ºr alle Endpoints
- ‚úÖ **Vollst√§ndige Dokumentation** mit Beispielen
- ‚úÖ **Schema-Validierung** und Error Handling
- ‚úÖ **Echtzeit-Tests** direkt im Browser

## üìä Praktische Beispiele

### Beispiel 1: Vollst√§ndige Qualit√§tsbewertung

**Anwendungsfall:** Bewertung von Bildungsinhalten vor Ver√∂ffentlichung

```python
import httpx

# Request
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Die deutsche Wiedervereinigung war ein komplexer politischer Prozess, der 1989 mit dem Fall der Berliner Mauer begann. Verschiedene politische Akteure trugen zu diesem historischen Ereignis bei, darunter B√ºrgerbewegungen in der DDR, die Politik der Sowjetunion unter Gorbatschow und die diplomatischen Bem√ºhungen der Bundesregierung.",
    "schemes": [
        "overall_quality",
        "rechtliche_compliance"
    ],
    "include_reasoning": true
})

# Response
result = response.json()
print(f"Gesamtqualit√§t: {result['results'][0]['value']}/5.0")
print(f"Rechtssicherheit: {'‚úì' if result['results'][1]['value'] == 1 else '‚úó'}")
```

**Erwartete Ausgabe:**
```json
{
    "results": [
        {
            "scheme_id": "overall_quality",
            "value": 4.2,
            "label": "Gute Qualit√§t",
            "confidence": 0.88,
            "reasoning": "Der Text zeigt hohe Sachrichtigkeit und Neutralit√§t...",
            "criteria": {
                "neutralitaet_old": {"value": 4, "label": "Weitgehend neutral"},
                "sachrichtigkeit_old": {"value": 5, "label": "Vollst√§ndig sachrichtig"},
                "aktualitaet_old": {"value": 4, "label": "Gut aktuell"}
            }
        },
        {
            "scheme_id": "rechtliche_compliance",
            "value": 1,
            "label": "PASS",
            "confidence": 0.95,
            "reasoning": "Alle rechtlichen Pr√ºfungen bestanden"
        }
    ]
}
```

### Beispiel 2: Detaillierte Qualit√§tspr√ºfung

**Anwendungsfall:** Wissenschaftliche Artikel mit Fokus auf Faktentreue

```python
# Request f√ºr detaillierte Bewertung
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Laut einer Studie der Universit√§t M√ºnchen aus dem Jahr 2023 zeigen 78% der befragten Sch√ºler verbesserte Lernleistungen bei Verwendung digitaler Medien. Die Studie basiert auf einer Stichprobe von 1.200 Sch√ºlern aus 15 bayerischen Gymnasien.",
    "schemes": [
        "sachrichtigkeit_new",
        "neutralitaet_new",
        "didaktik_methodik_new"
    ],
    "include_reasoning": true
})

# Detaillierte Kriterien-Analyse
for result in response.json()['results']:
    print(f"\n{result['scheme_id']}: {result['value']}/5.0")
    for criterion, details in result['criteria'].items():
        print(f"  - {criterion}: {details['value']} - {details['reasoning'][:50]}...")
```

### Beispiel 3: Compliance-Schnellpr√ºfung

**Anwendungsfall:** User-Generated Content vor Freischaltung

```python
# Rechtliche Schnellpr√ºfung
response = httpx.post("http://localhost:8001/evaluate", json={
    "text": "Das ist ein normaler Kommentar zu einem Bildungsthema ohne problematische Inhalte.",
    "schemes": [
        "jugendschutz_gate",
        "strafrecht_gate",
        "persoenlichkeitsrechte_gate"
    ],
    "include_reasoning": false  # Schnelle Pr√ºfung ohne Details
})

# Einfache Pass/Fail Auswertung
all_passed = all(r['value'] == 1 for r in response.json()['results'])
print(f"Content freigegeben: {'‚úì' if all_passed else '‚úó'}")

# Detaillierte Fehleranalyse bei Problemen
if not all_passed:
    failed_gates = [r['scheme_id'] for r in response.json()['results'] if r['value'] == 0]
    print(f"Problematische Bereiche: {', '.join(failed_gates)}")
```

### Beispiel 4: Batch-Verarbeitung

**Anwendungsfall:** Bewertung mehrerer Inhalte

```python
import asyncio
import httpx

async def evaluate_content(client, text, schemes):
    """Einzelne Inhaltsbewertung"""
    response = await client.post("/evaluate", json={
        "text": text,
        "schemes": schemes,
        "include_reasoning": false
    })
    return response.json()

async def batch_evaluate():
    """Batch-Bewertung mehrerer Inhalte"""
    contents = [
        "Lerninhalt 1: Geschichte der Demokratie...",
        "Lerninhalt 2: Mathematische Grundlagen...",
        "Lerninhalt 3: Naturwissenschaftliche Experimente..."
    ]
    
    async with httpx.AsyncClient(base_url="http://localhost:8001") as client:
        tasks = [
            evaluate_content(client, content, ["overall_quality", "rechtliche_compliance"])
            for content in contents
        ]
        results = await asyncio.gather(*tasks)
    
    # Ergebnisse auswerten
    for i, result in enumerate(results):
        quality = result['results'][0]['value']
        compliance = result['results'][1]['value']
        print(f"Inhalt {i+1}: Qualit√§t {quality}/5.0, Compliance {'‚úì' if compliance else '‚úó'}")

# Ausf√ºhrung
asyncio.run(batch_evaluate())
```

### Beispiel 5: Error Handling

**Anwendungsfall:** Robuste Fehlerbehandlung

```python
import httpx
from typing import Dict, Any

def safe_evaluate(text: str, schemes: list) -> Dict[str, Any]:
    """Sichere Bewertung mit Fehlerbehandlung"""
    try:
        response = httpx.post(
            "http://localhost:8001/evaluate",
            json={
                "text": text,
                "schemes": schemes,
                "include_reasoning": true
            },
            timeout=30.0  # 30 Sekunden Timeout
        )
        response.raise_for_status()
        return {
            "success": True,
            "data": response.json()
        }
    
    except httpx.TimeoutException:
        return {
            "success": False,
            "error": "Timeout: Bewertung dauerte zu lange",
            "retry_recommended": True
        }
    
    except httpx.HTTPStatusError as e:
        return {
            "success": False,
            "error": f"HTTP {e.response.status_code}: {e.response.text}",
            "retry_recommended": e.response.status_code >= 500
        }
    
    except Exception as e:
        return {
            "success": False,
            "error": f"Unerwarteter Fehler: {str(e)}",
            "retry_recommended": False
        }

# Verwendung
result = safe_evaluate(
    "Beispieltext f√ºr Bewertung",
    ["neutralitaet_new", "sachrichtigkeit_new"]
)

if result["success"]:
    print("Bewertung erfolgreich:", result["data"])
else:
    print("Fehler:", result["error"])
    if result["retry_recommended"]:
        print("Wiederholung empfohlen")
```

## ‚öñÔ∏è Deutsche Rechtskonformit√§t

### Abgedeckte Gesetze
- ‚úÖ **Strafgesetzbuch (StGB)**: Volksverhetzung, Gewaltverherrlichung, Beleidigung
- ‚úÖ **Jugendschutzgesetz (JuSchG)**: Altersgerechte Inhalte, Entwicklungsschutz
- ‚úÖ **DSGVO**: Datenschutz, Pers√∂nlichkeitsrechte
- ‚úÖ **Kunsturhebergesetz (KUG)**: Bildrechte, Recht am eigenen Bild
- ‚úÖ **NetzDG**: Strafbare Inhalte in sozialen Netzwerken
- ‚úÖ **Digital Services Act (DSA)**: EU-Digitalrecht

### Automatische Risikobewertung
- üî¥ **Critical**: Schwere Straftaten ‚Üí Sofortige Sperrung
- üü† **High**: Erhebliche Rechtsverst√∂√üe ‚Üí Manuelle Pr√ºfung
- üü° **Medium**: Zivilrechtliche Folgen ‚Üí √úberarbeitung empfohlen
- üü¢ **Low**: Geringf√ºgige Verst√∂√üe ‚Üí Hinweis ausreichend

## üéØ Best Practices

### Schema-Auswahl f√ºr verschiedene Anwendungsf√§lle

#### üìö **Bildungsinhalte (Empfohlen)**
```json
{"schemes": ["overall_quality", "rechtliche_compliance"]}
```

#### üë• **User-Generated Content**
```json
{"schemes": ["jugendschutz_gate", "strafrecht_gate", "persoenlichkeitsrechte_gate"]}
```

#### üî¨ **Wissenschaftliche Texte**
```json
{"schemes": ["sachrichtigkeit_new", "neutralitaet_new"]}
```

#### ‚ö° **Schnelle Qualit√§tspr√ºfung**
```json
{"schemes": ["neutralitaet_old", "sachrichtigkeit_old"], "include_reasoning": false}
```

### Performance & Zuverl√§ssigkeit
- ‚úÖ **Automatische Fehlerbehandlung** f√ºr ung√ºltige Schema-IDs
- ‚úÖ **Timeout-Protection** f√ºr KI-Bewertungen
- ‚úÖ **Dependency-Validation** f√ºr derived Schemas
- ‚úÖ **Rate Limiting** ber√ºcksichtigen (OpenAI API)
- ‚úÖ **Retry-Logic** f√ºr tempor√§re Fehler

## üîß Entwicklung & Erweiterung

### API Status & Monitoring
```bash
# API Health Check
curl http://localhost:8001/health

# Alle verf√ºgbaren Schemas auflisten
curl http://localhost:8001/schemes

# Test-Bewertung durchf√ºhren
curl -X POST http://localhost:8001/evaluate \
  -H "Content-Type: application/json" \
  -d '{"text":"Testinhalt", "schemes":["neutralitaet_old"]}'
```

### Neues Schema erstellen
1. YAML-Datei in `schemes/` erstellen
2. Schema-Typ und Parameter definieren
3. Kriterien und Regeln spezifizieren
4. API neu starten f√ºr automatisches Laden

### Debugging & Logs
- ‚úÖ **Structured Logging** mit Loguru
- ‚úÖ **Request/Response Tracing**
- ‚úÖ **Error Details** in API Responses
- ‚úÖ **Schema Loading Status** beim Startup

## üìà Produktionsstatus

### ‚úÖ Funktionsf√§hige Features
- üü¢ **API Server**: L√§uft stabil auf Port 8001
- üü¢ **Alle Endpoints**: Health, Schemes, Evaluate funktionsf√§hig
- üü¢ **15 Bewertungsschemas**: Vollst√§ndig geladen und getestet
- üü¢ **KI-Integration**: OpenAI GPT-4 Bewertungen
- üü¢ **Swagger UI**: Vollst√§ndige interaktive Dokumentation
- üü¢ **Error Handling**: Robuste Fehlerbehandlung
- üü¢ **Schema Validation**: Pydantic-basierte Validierung

### üîÑ Letzte Updates (2025-01-18)
- ‚úÖ Fixed Swagger UI "Try it out" Funktionalit√§t
- ‚úÖ Erweiterte API-Dokumentation mit Beispielen
- ‚úÖ Verbesserte Schema-Validierung f√ºr Binary Gates
- ‚úÖ Dependency Injection Kompatibilit√§t

## üìù Lizenz & Rechtliches

Dieses System implementiert deutsche Rechtsstandards und ist f√ºr den Einsatz in Deutschland optimiert. Bei internationaler Nutzung sind lokale Gesetze zu beachten.

**‚ö†Ô∏è Haftungsausschluss**: Die automatische Rechtspr√ºfung ersetzt keine juristische Beratung. Bei kritischen Inhalten sollte immer eine manuelle Pr√ºfung erfolgen.

---

**üöÄ Ready for Production** | **ü§ñ LLM as Judge** | **üìö Full Documentation** | **üîß Easy to Extend**
